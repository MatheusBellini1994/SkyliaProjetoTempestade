{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('INMET_2023.csv', encoding='latin1', sep=';')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Clima_inter_2019_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover as colunas indesejadas\n",
    "df2 = df2.drop(columns=['Unnamed: 0', 'Umi. Ins. (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Hora (UTC)</th>\n",
       "      <th>Temp. Ins. (C)</th>\n",
       "      <th>Vel. Vento (m/s)</th>\n",
       "      <th>Raj. Vento (m/s)</th>\n",
       "      <th>Chuva (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>21.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>20.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>20.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>20.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34359</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34360</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34361</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>21.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34362</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34363</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>20.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34364 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Data Hora (UTC)  Temp. Ins. (C)  Vel. Vento (m/s)  \\\n",
       "0      2019-01-01   00:00:00            21.5               5.9   \n",
       "1      2019-01-01   01:00:00            21.1               4.6   \n",
       "2      2019-01-01   02:00:00            20.7               4.4   \n",
       "3      2019-01-01   03:00:00            20.5               4.0   \n",
       "4      2019-01-01   04:00:00            20.7               4.2   \n",
       "...           ...        ...             ...               ...   \n",
       "34359  2022-12-31   19:00:00            19.4               6.6   \n",
       "34360  2022-12-31   20:00:00            21.0               7.4   \n",
       "34361  2022-12-31   21:00:00            21.7               5.4   \n",
       "34362  2022-12-31   22:00:00            20.9               5.3   \n",
       "34363  2022-12-31   23:00:00            20.5               5.3   \n",
       "\n",
       "       Raj. Vento (m/s)  Chuva (mm)  \n",
       "0                   2.3         0.0  \n",
       "1                   2.1         0.0  \n",
       "2                   1.6         0.0  \n",
       "3                   1.7         0.0  \n",
       "4                   1.9         0.0  \n",
       "...                 ...         ...  \n",
       "34359               0.8        32.0  \n",
       "34360               2.0         2.0  \n",
       "34361               1.5         0.0  \n",
       "34362               2.4         0.0  \n",
       "34363               1.9         0.0  \n",
       "\n",
       "[34364 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma correta de substituir valores NaN por 0\n",
    "df1['Chuva (mm)'] = df1['Chuva (mm)'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores não numéricos na coluna 'Temp. Ins. (C)':\n",
      "948     ;\n",
      "3753    ;\n",
      "3765    ;\n",
      "3776    ;\n",
      "3791    ;\n",
      "3808    ;\n",
      "3824    ;\n",
      "4076    ;\n",
      "4088    ;\n",
      "4104    ;\n",
      "4119    ;\n",
      "4136    ;\n",
      "4154    ;\n",
      "4175    ;\n",
      "4195    ;\n",
      "4336    ;\n",
      "4347    ;\n",
      "4357    ;\n",
      "4367    ;\n",
      "4509    ;\n",
      "4531    ;\n",
      "4546    ;\n",
      "4549    ;\n",
      "5002    ;\n",
      "5566    ;\n",
      "5577    ;\n",
      "5671    ;\n",
      "6324    ;\n",
      "Name: Temp. Ins. (C), dtype: object\n",
      "Valores não numéricos na coluna 'Vel. Vento (m/s)':\n",
      "3765    ;\n",
      "3776    ;\n",
      "3791    ;\n",
      "3808    ;\n",
      "3824    ;\n",
      "       ..\n",
      "8583    ;\n",
      "8584    ;\n",
      "8585    ;\n",
      "8586    ;\n",
      "8587    ;\n",
      "Name: Vel. Vento (m/s), Length: 363, dtype: object\n",
      "Valores não numéricos na coluna 'Raj. Vento (m/s)':\n",
      "3765    ;\n",
      "3776    ;\n",
      "3791    ;\n",
      "3808    ;\n",
      "3824    ;\n",
      "4076    ;\n",
      "4088    ;\n",
      "4104    ;\n",
      "4119    ;\n",
      "4136    ;\n",
      "4154    ;\n",
      "4175    ;\n",
      "4195    ;\n",
      "4336    ;\n",
      "4347    ;\n",
      "4357    ;\n",
      "4367    ;\n",
      "4531    ;\n",
      "4546    ;\n",
      "4549    ;\n",
      "5671    ;\n",
      "Name: Raj. Vento (m/s), dtype: object\n",
      "Valores não numéricos na coluna 'Chuva (mm)':\n",
      "3765                ;\n",
      "3776                ;\n",
      "3791                ;\n",
      "3808                ;\n",
      "3824                ;\n",
      "4076                ;\n",
      "4088                ;\n",
      "4104                ;\n",
      "4119                ;\n",
      "4136                ;\n",
      "4154                ;\n",
      "4175                ;\n",
      "4195                ;\n",
      "4336                ;\n",
      "4347                ;\n",
      "4357                ;\n",
      "4367                ;\n",
      "4443    \\n11/07/2023\"\n",
      "4531                ;\n",
      "4546                ;\n",
      "4549                ;\n",
      "5671                ;\n",
      "Name: Chuva (mm), dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores não numéricos nas colunas especificadas\n",
    "colunas_para_verificar = ['Temp. Ins. (C)', 'Vel. Vento (m/s)', 'Raj. Vento (m/s)', 'Chuva (mm)']\n",
    "\n",
    "for coluna in colunas_para_verificar:\n",
    "    # Converter a coluna para numérico, substituindo valores não numéricos por NaN\n",
    "    nao_numericos = df1[pd.to_numeric(df1[coluna], errors='coerce').isna()]\n",
    "    \n",
    "    # Filtrar apenas os valores não numéricos\n",
    "    if not nao_numericos.empty:\n",
    "        print(f\"Valores não numéricos na coluna '{coluna}':\")\n",
    "        print(nao_numericos[coluna])\n",
    "    else:\n",
    "        print(f\"Nenhum valor não numérico encontrado na coluna '{coluna}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir o valor específico '\\n11/07/2023\"' por 0 na coluna 'Chuva (mm)'\n",
    "df1['Chuva (mm)'] = df1['Chuva (mm)'].replace('\\n11/07/2023\"', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp. Ins. (C)       28\n",
      "Vel. Vento (m/s)    363\n",
      "Raj. Vento (m/s)     21\n",
      "Chuva (mm)           21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Substituir os valores não numéricos por NaN em todas as colunas relevantes\n",
    "colunas_para_verificar = ['Temp. Ins. (C)', 'Vel. Vento (m/s)', 'Raj. Vento (m/s)', 'Chuva (mm)']\n",
    "\n",
    "# Substituir ';' por NaN nas colunas selecionadas\n",
    "df1[colunas_para_verificar] = df1[colunas_para_verificar].replace(';', np.nan)\n",
    "\n",
    "# Agora você pode verificar se há valores ausentes (NaN) e tratá-los\n",
    "print(df1[colunas_para_verificar].isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas restantes: 8588\n",
      "Data                16/07/2023\"\n",
      "Hora (UTC)                  200\n",
      "Temp. Ins. (C)             11.9\n",
      "Vel. Vento (m/s)            1.2\n",
      "Raj. Vento (m/s)            3.5\n",
      "Chuva (mm)                    0\n",
      "Name: 4545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Excluir linhas com valores NaN nas colunas especificadas\n",
    "colunas_para_excluir_nan = ['Temp. Ins. (C)', 'Vel. Vento (m/s)', 'Raj. Vento (m/s)']\n",
    "\n",
    "# Remover linhas onde qualquer uma das colunas especificadas contém NaN\n",
    "df1_filtered = df1.dropna(subset=colunas_para_excluir_nan)\n",
    "\n",
    "# Verificar a quantidade de linhas restantes\n",
    "print(f'Número de linhas restantes: {df1.shape[0]}')\n",
    "\n",
    "# Opcional: Ver a linha 4546 após a remoção\n",
    "if len(df1) > 4545:\n",
    "    print(df1.iloc[4545])\n",
    "else:\n",
    "    print(\"A linha 4546 não está mais disponível após a exclusão.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas para Temperatura (°C):\n",
      "  Max: 37.9\n",
      "  Min: 7.7\n",
      "  Media: 20.22542056074766\n",
      "  Moda: 19.9\n",
      "  Mediana: 19.8\n",
      "Estatísticas para Velocidade do Vento (m/s):\n",
      "  Max: 23.6\n",
      "  Min: 0.1\n",
      "  Media: 1.9826018237082066\n",
      "  Moda: 1.3\n",
      "  Mediana: 1.8\n",
      "Estatísticas para Rajada do Vento (m/s):\n",
      "  Max: 100.0\n",
      "  Min: 0.0\n",
      "  Media: 5.1022995214194\n",
      "  Moda: 0.0\n",
      "  Mediana: 4.9\n",
      "Estatísticas para Chuva (mm):\n",
      "  Max: 46.2\n",
      "  Min: 0.0\n",
      "  Media: 0.1069569277460021\n",
      "  Moda: 0.0\n",
      "  Mediana: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Converter as colunas para tipo numérico, se necessário\n",
    "df1['Temp. Ins. (C)'] = pd.to_numeric(df1['Temp. Ins. (C)'], errors='coerce')\n",
    "df1['Vel. Vento (m/s)'] = pd.to_numeric(df1['Vel. Vento (m/s)'], errors='coerce')\n",
    "df1['Raj. Vento (m/s)'] = pd.to_numeric(df1['Raj. Vento (m/s)'], errors='coerce')\n",
    "df1['Chuva (mm)'] = pd.to_numeric(df1['Chuva (mm)'], errors='coerce')\n",
    "\n",
    "# Calcular as estatísticas desejadas\n",
    "estatisticas = {\n",
    "    'Temperatura (°C)': {\n",
    "        'Max': df1['Temp. Ins. (C)'].max(),\n",
    "        'Min': df1['Temp. Ins. (C)'].min(),\n",
    "        'Media': df1['Temp. Ins. (C)'].mean(),\n",
    "        'Moda': df1['Temp. Ins. (C)'].mode()[0],\n",
    "        'Mediana': df1['Temp. Ins. (C)'].median(),\n",
    "    },\n",
    "    'Velocidade do Vento (m/s)': {\n",
    "        'Max': df1['Vel. Vento (m/s)'].max(),\n",
    "        'Min': df1['Vel. Vento (m/s)'].min(),\n",
    "        'Media': df1['Vel. Vento (m/s)'].mean(),\n",
    "        'Moda': df1['Vel. Vento (m/s)'].mode()[0],\n",
    "        'Mediana': df1['Vel. Vento (m/s)'].median(),\n",
    "    },\n",
    "    'Rajada do Vento (m/s)': {\n",
    "        'Max': df1['Raj. Vento (m/s)'].max(),\n",
    "        'Min': df1['Raj. Vento (m/s)'].min(),\n",
    "        'Media': df1['Raj. Vento (m/s)'].mean(),\n",
    "        'Moda': df1['Raj. Vento (m/s)'].mode()[0],\n",
    "        'Mediana': df1['Raj. Vento (m/s)'].median(),\n",
    "    },\n",
    "    'Chuva (mm)': {\n",
    "        'Max': df1['Chuva (mm)'].max(),\n",
    "        'Min': df1['Chuva (mm)'].min(),\n",
    "        'Media': df1['Chuva (mm)'].mean(),\n",
    "        'Moda': df1['Chuva (mm)'].mode()[0],\n",
    "        'Mediana': df1['Chuva (mm)'].median(),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Exibir as estatísticas\n",
    "for coluna, stats in estatisticas.items():\n",
    "    print(f'Estatísticas para {coluna}:')\n",
    "    for stat, valor in stats.items():\n",
    "        print(f'  {stat}: {valor}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas onde 'Vel. Vento (m/s)' ou 'Raj. Vento (m/s)' são NaN\n",
    "df1 = df1.dropna(subset=['Vel. Vento (m/s)', 'Raj. Vento (m/s)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir todas as vírgulas por pontos em todos os DataFrames\n",
    "df1 = df1.replace(',', '.', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"2023-01-01\" doesn't match format \"%d/%m/%Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Converter a coluna 'Data' para o formato YYYY-MM-DD\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"2023-01-01\" doesn't match format \"%d/%m/%Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# 1. Remover aspas da coluna 'Data'\n",
    "df1['Data'] = df1['Data'].str.replace('\"', '', regex=False)\n",
    "\n",
    "# 2. Converter a coluna 'Data' para o formato YYYY-MM-DD\n",
    "df1['Data'] = pd.to_datetime(df1['Data'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converter a coluna 'Hora (UTC)' para HH:MM:SS\n",
    "def format_time(value):\n",
    "    time_str = f\"{value:04}\"\n",
    "    return f\"{time_str[:2]}:{time_str[2:]}:00\"\n",
    "\n",
    "df1['Hora (UTC)'] = df1['Hora (UTC)'].apply(format_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df2, df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('Clima_inter_2019_2023.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
