{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do SMOTE: 29428 quedas de energia.\n",
      "Depois do SMOTE: 73593 quedas de energia.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 12ms/step - accuracy: 0.6282 - loss: 0.6540 - val_accuracy: 0.0236 - val_loss: 1.0136\n",
      "Epoch 2/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 12ms/step - accuracy: 0.6334 - loss: 0.6479 - val_accuracy: 0.1318 - val_loss: 0.9577\n",
      "Epoch 3/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6348 - loss: 0.6457 - val_accuracy: 0.1731 - val_loss: 0.9168\n",
      "Epoch 4/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 12ms/step - accuracy: 0.6321 - loss: 0.6468 - val_accuracy: 0.2658 - val_loss: 0.8642\n",
      "Epoch 5/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6328 - loss: 0.6461 - val_accuracy: 0.0345 - val_loss: 1.0599\n",
      "Epoch 6/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 14ms/step - accuracy: 0.6314 - loss: 0.6457 - val_accuracy: 0.0707 - val_loss: 1.0610\n",
      "Epoch 7/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.6321 - loss: 0.6453 - val_accuracy: 0.0772 - val_loss: 1.0179\n",
      "Epoch 8/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6324 - loss: 0.6448 - val_accuracy: 0.0774 - val_loss: 1.0109\n",
      "Epoch 9/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - accuracy: 0.6350 - loss: 0.6436 - val_accuracy: 0.1886 - val_loss: 0.9360\n",
      "Epoch 10/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6327 - loss: 0.6445 - val_accuracy: 0.1046 - val_loss: 0.9844\n",
      "Epoch 11/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 13ms/step - accuracy: 0.6338 - loss: 0.6449 - val_accuracy: 0.1312 - val_loss: 0.9652\n",
      "Epoch 12/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 12ms/step - accuracy: 0.6341 - loss: 0.6443 - val_accuracy: 0.1678 - val_loss: 0.9558\n",
      "Epoch 13/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6322 - loss: 0.6445 - val_accuracy: 0.1571 - val_loss: 0.9161\n",
      "Epoch 14/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6361 - loss: 0.6415 - val_accuracy: 0.1623 - val_loss: 0.9605\n",
      "Epoch 15/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6356 - loss: 0.6432 - val_accuracy: 0.2273 - val_loss: 0.9410\n",
      "Epoch 16/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 13ms/step - accuracy: 0.6362 - loss: 0.6425 - val_accuracy: 0.2512 - val_loss: 0.8888\n",
      "Epoch 17/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6374 - loss: 0.6421 - val_accuracy: 0.1444 - val_loss: 0.9928\n",
      "Epoch 18/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 13ms/step - accuracy: 0.6360 - loss: 0.6423 - val_accuracy: 0.2210 - val_loss: 0.8779\n",
      "Epoch 19/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6346 - loss: 0.6435 - val_accuracy: 0.2118 - val_loss: 0.9104\n",
      "Epoch 20/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 11ms/step - accuracy: 0.6377 - loss: 0.6418 - val_accuracy: 0.0841 - val_loss: 0.9862\n",
      "Epoch 21/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10ms/step - accuracy: 0.6362 - loss: 0.6415 - val_accuracy: 0.1408 - val_loss: 0.9347\n",
      "Epoch 22/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.6342 - loss: 0.6438 - val_accuracy: 0.1571 - val_loss: 0.9606\n",
      "Epoch 23/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.6352 - loss: 0.6427 - val_accuracy: 0.2206 - val_loss: 0.9061\n",
      "Epoch 24/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 9ms/step - accuracy: 0.6369 - loss: 0.6418 - val_accuracy: 0.1053 - val_loss: 0.9810\n",
      "Epoch 25/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - accuracy: 0.6362 - loss: 0.6413 - val_accuracy: 0.1229 - val_loss: 1.0248\n",
      "Epoch 26/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 12ms/step - accuracy: 0.6388 - loss: 0.6410 - val_accuracy: 0.1944 - val_loss: 0.9149\n",
      "Epoch 27/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6365 - loss: 0.6425 - val_accuracy: 0.1701 - val_loss: 0.9565\n",
      "Epoch 28/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.6354 - loss: 0.6427 - val_accuracy: 0.1469 - val_loss: 0.9451\n",
      "Epoch 29/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10ms/step - accuracy: 0.6348 - loss: 0.6425 - val_accuracy: 0.0800 - val_loss: 1.0042\n",
      "Epoch 30/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - accuracy: 0.6370 - loss: 0.6418 - val_accuracy: 0.1791 - val_loss: 0.9918\n",
      "Epoch 31/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 12ms/step - accuracy: 0.6360 - loss: 0.6422 - val_accuracy: 0.2384 - val_loss: 0.8848\n",
      "Epoch 32/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 15ms/step - accuracy: 0.6387 - loss: 0.6416 - val_accuracy: 0.1870 - val_loss: 0.9441\n",
      "Epoch 33/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 10ms/step - accuracy: 0.6361 - loss: 0.6422 - val_accuracy: 0.2425 - val_loss: 0.9326\n",
      "Epoch 34/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10ms/step - accuracy: 0.6377 - loss: 0.6407 - val_accuracy: 0.1504 - val_loss: 0.9987\n",
      "Epoch 35/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 11ms/step - accuracy: 0.6371 - loss: 0.6415 - val_accuracy: 0.1947 - val_loss: 0.9361\n",
      "Epoch 36/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.6365 - loss: 0.6424 - val_accuracy: 0.1614 - val_loss: 0.9870\n",
      "Epoch 37/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 14ms/step - accuracy: 0.6371 - loss: 0.6419 - val_accuracy: 0.1798 - val_loss: 0.9433\n",
      "Epoch 38/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6361 - loss: 0.6420 - val_accuracy: 0.1395 - val_loss: 1.0319\n",
      "Epoch 39/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - accuracy: 0.6366 - loss: 0.6419 - val_accuracy: 0.1152 - val_loss: 0.9878\n",
      "Epoch 40/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.6395 - loss: 0.6407 - val_accuracy: 0.1512 - val_loss: 0.9551\n",
      "Epoch 41/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - accuracy: 0.6383 - loss: 0.6407 - val_accuracy: 0.1686 - val_loss: 0.9306\n",
      "Epoch 42/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - accuracy: 0.6384 - loss: 0.6403 - val_accuracy: 0.1680 - val_loss: 0.9032\n",
      "Epoch 43/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.6371 - loss: 0.6419 - val_accuracy: 0.1455 - val_loss: 0.9180\n",
      "Epoch 44/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 24ms/step - accuracy: 0.6362 - loss: 0.6416 - val_accuracy: 0.1480 - val_loss: 1.0271\n",
      "Epoch 45/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.6370 - loss: 0.6415 - val_accuracy: 0.2182 - val_loss: 0.9265\n",
      "Epoch 46/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 24ms/step - accuracy: 0.6364 - loss: 0.6412 - val_accuracy: 0.2012 - val_loss: 0.9217\n",
      "Epoch 47/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.6376 - loss: 0.6412 - val_accuracy: 0.1458 - val_loss: 0.9712\n",
      "Epoch 48/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 21ms/step - accuracy: 0.6374 - loss: 0.6407 - val_accuracy: 0.1556 - val_loss: 0.9533\n",
      "Epoch 49/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.6376 - loss: 0.6415 - val_accuracy: 0.1590 - val_loss: 0.9404\n",
      "Epoch 50/50\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.6343 - loss: 0.6427 - val_accuracy: 0.1758 - val_loss: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ab92095070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Carregando os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Imputando valores faltantes para a coluna 'Temp. Ins. (C)' em df3\n",
    "df3['Temp. Ins. (C)'] = df3['Temp. Ins. (C)'].fillna(df3['Temp. Ins. (C)'].mean())\n",
    "\n",
    "# Concatenando os DataFrames\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# Transformando a coluna 'num_ocorrencias' em binária (0: não ocorreu, 1: ocorreu)\n",
    "df['num_ocorrencias'] = df['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# Separando a variável alvo\n",
    "y = df['num_ocorrencias']\n",
    "\n",
    "# Definindo as features (X), excluindo a coluna alvo\n",
    "X = df.drop(columns=['num_ocorrencias'])\n",
    "\n",
    "# Normalizando os dados \n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Separando em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializando o SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "# Aplicando o SMOTE nos dados de treino\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificando a quantidade de amostras após o SMOTE\n",
    "print(f'Antes do SMOTE: {len(y_train[y_train == 1])} quedas de energia.')\n",
    "print(f'Depois do SMOTE: {len(y_resampled[y_resampled == 1])} quedas de energia.')\n",
    "\n",
    "# Modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1), y_resampled, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m805/805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Acurácia: 0.7041\n",
      "Sensibilidade (Recall): 0.1789\n",
      "AUC: 0.5481\n",
      "Especificidade: 0.9174\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Converter previsões e verdadeiras etiquetas para binário se necessário\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "y_test_binary = (y_test > threshold).astype(int)\n",
    "\n",
    "# Avaliação do modelo\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "recall = recall_score(y_test_binary, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_test_binary, y_pred_binary)\n",
    "conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "\n",
    "# Cálculo da especificidade\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Exibir resultados\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote_Previsao_3cvs_2019-2023_erro.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do SMOTE: 29428 quedas de energia.\n",
      "Depois do SMOTE: 73593 quedas de energia.\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 0.6279 - loss: 0.6567 - val_accuracy: 0.1315 - val_loss: 0.9170\n",
      "Epoch 2/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6310 - loss: 0.6495 - val_accuracy: 0.0567 - val_loss: 0.9741\n",
      "Epoch 3/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6316 - loss: 0.6479 - val_accuracy: 0.1533 - val_loss: 0.9403\n",
      "Epoch 4/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6320 - loss: 0.6470 - val_accuracy: 0.0460 - val_loss: 1.0048\n",
      "Epoch 5/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6325 - loss: 0.6465 - val_accuracy: 0.2294 - val_loss: 0.9166\n",
      "Epoch 6/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6370 - loss: 0.6440 - val_accuracy: 0.1768 - val_loss: 0.9031\n",
      "Epoch 7/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6316 - loss: 0.6466 - val_accuracy: 0.0719 - val_loss: 1.0341\n",
      "Epoch 8/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6318 - loss: 0.6455 - val_accuracy: 0.1693 - val_loss: 0.9428\n",
      "Epoch 9/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6332 - loss: 0.6453 - val_accuracy: 0.0420 - val_loss: 1.0616\n",
      "Epoch 10/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6315 - loss: 0.6465 - val_accuracy: 0.1340 - val_loss: 0.9524\n",
      "Epoch 11/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6320 - loss: 0.6450 - val_accuracy: 0.1483 - val_loss: 0.9511\n",
      "Epoch 12/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6360 - loss: 0.6437 - val_accuracy: 0.1203 - val_loss: 0.9565\n",
      "Epoch 13/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6353 - loss: 0.6437 - val_accuracy: 0.1306 - val_loss: 0.9509\n",
      "Epoch 14/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - accuracy: 0.6340 - loss: 0.6447 - val_accuracy: 0.1471 - val_loss: 0.9643\n",
      "Epoch 15/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6365 - loss: 0.6430 - val_accuracy: 0.1164 - val_loss: 0.9705\n",
      "Epoch 16/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6352 - loss: 0.6436 - val_accuracy: 0.2455 - val_loss: 0.8916\n",
      "Epoch 17/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6305 - loss: 0.6459 - val_accuracy: 0.2283 - val_loss: 0.9175\n",
      "Epoch 18/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6338 - loss: 0.6441 - val_accuracy: 0.1151 - val_loss: 1.0026\n",
      "Epoch 19/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6360 - loss: 0.6425 - val_accuracy: 0.1746 - val_loss: 0.9492\n",
      "Epoch 20/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6330 - loss: 0.6443 - val_accuracy: 0.0837 - val_loss: 1.0033\n",
      "Epoch 21/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6350 - loss: 0.6432 - val_accuracy: 0.1231 - val_loss: 0.9947\n",
      "Epoch 22/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6357 - loss: 0.6430 - val_accuracy: 0.2060 - val_loss: 0.9142\n",
      "Epoch 23/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6306 - loss: 0.6458 - val_accuracy: 0.1250 - val_loss: 0.9962\n",
      "Epoch 24/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - accuracy: 0.6325 - loss: 0.6453 - val_accuracy: 0.1287 - val_loss: 0.9791\n",
      "Epoch 25/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6366 - loss: 0.6426 - val_accuracy: 0.1753 - val_loss: 0.9104\n",
      "Epoch 26/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.6348 - loss: 0.6427 - val_accuracy: 0.1792 - val_loss: 0.9190\n",
      "Epoch 27/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6429 - val_accuracy: 0.1838 - val_loss: 0.9725\n",
      "Epoch 28/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6335 - loss: 0.6434 - val_accuracy: 0.1316 - val_loss: 0.9735\n",
      "Epoch 29/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6350 - loss: 0.6435 - val_accuracy: 0.2657 - val_loss: 0.8570\n",
      "Epoch 30/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 32ms/step - accuracy: 0.6332 - loss: 0.6436 - val_accuracy: 0.1502 - val_loss: 0.9324\n",
      "Epoch 31/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 30ms/step - accuracy: 0.6348 - loss: 0.6426 - val_accuracy: 0.1242 - val_loss: 0.9684\n",
      "Epoch 32/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 31ms/step - accuracy: 0.6350 - loss: 0.6418 - val_accuracy: 0.1010 - val_loss: 0.9892\n",
      "Epoch 33/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 31ms/step - accuracy: 0.6355 - loss: 0.6422 - val_accuracy: 0.1323 - val_loss: 0.9618\n",
      "Epoch 34/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 30ms/step - accuracy: 0.6361 - loss: 0.6421 - val_accuracy: 0.1669 - val_loss: 0.9862\n",
      "Epoch 35/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 29ms/step - accuracy: 0.6359 - loss: 0.6420 - val_accuracy: 0.2295 - val_loss: 0.8970\n",
      "Epoch 36/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6333 - loss: 0.6438 - val_accuracy: 0.1556 - val_loss: 0.9357\n",
      "Epoch 37/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6343 - loss: 0.6424 - val_accuracy: 0.1176 - val_loss: 1.0011\n",
      "Epoch 38/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 32ms/step - accuracy: 0.6371 - loss: 0.6424 - val_accuracy: 0.1356 - val_loss: 0.9559\n",
      "Epoch 39/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6373 - loss: 0.6418 - val_accuracy: 0.1672 - val_loss: 0.9767\n",
      "Epoch 40/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6334 - loss: 0.6437 - val_accuracy: 0.1940 - val_loss: 0.9057\n",
      "Epoch 41/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6357 - loss: 0.6423 - val_accuracy: 0.1572 - val_loss: 0.9621\n",
      "Epoch 42/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.6371 - loss: 0.6415 - val_accuracy: 0.2089 - val_loss: 0.9267\n",
      "Epoch 43/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6347 - loss: 0.6432 - val_accuracy: 0.1414 - val_loss: 0.9774\n",
      "Epoch 44/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6365 - loss: 0.6425 - val_accuracy: 0.1929 - val_loss: 0.9261\n",
      "Epoch 45/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 32ms/step - accuracy: 0.6384 - loss: 0.6414 - val_accuracy: 0.1923 - val_loss: 0.9438\n",
      "Epoch 46/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6355 - loss: 0.6426 - val_accuracy: 0.1868 - val_loss: 0.8938\n",
      "Epoch 47/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.6356 - loss: 0.6411 - val_accuracy: 0.1103 - val_loss: 0.9487\n",
      "Epoch 48/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6360 - loss: 0.6420 - val_accuracy: 0.2137 - val_loss: 0.9062\n",
      "Epoch 49/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.6357 - loss: 0.6426 - val_accuracy: 0.0981 - val_loss: 0.9942\n",
      "Epoch 50/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.6346 - loss: 0.6425 - val_accuracy: 0.1107 - val_loss: 1.0210\n",
      "Epoch 51/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 30ms/step - accuracy: 0.6350 - loss: 0.6428 - val_accuracy: 0.1487 - val_loss: 0.9283\n",
      "Epoch 52/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6352 - loss: 0.6426 - val_accuracy: 0.1961 - val_loss: 0.9383\n",
      "Epoch 53/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.6346 - loss: 0.6423 - val_accuracy: 0.1928 - val_loss: 0.9181\n",
      "Epoch 54/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6363 - loss: 0.6425 - val_accuracy: 0.1801 - val_loss: 0.9404\n",
      "Epoch 55/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6379 - loss: 0.6413 - val_accuracy: 0.1469 - val_loss: 1.0088\n",
      "Epoch 56/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6340 - loss: 0.6435 - val_accuracy: 0.1456 - val_loss: 0.9539\n",
      "Epoch 57/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 31ms/step - accuracy: 0.6362 - loss: 0.6418 - val_accuracy: 0.2321 - val_loss: 0.8944\n",
      "Epoch 58/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6357 - loss: 0.6413 - val_accuracy: 0.1334 - val_loss: 0.9666\n",
      "Epoch 59/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 21ms/step - accuracy: 0.6371 - loss: 0.6412 - val_accuracy: 0.1888 - val_loss: 0.9478\n",
      "Epoch 60/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.6345 - loss: 0.6425 - val_accuracy: 0.1401 - val_loss: 0.9457\n",
      "Epoch 61/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6345 - loss: 0.6424 - val_accuracy: 0.1832 - val_loss: 0.9724\n",
      "Epoch 62/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6377 - loss: 0.6417 - val_accuracy: 0.2264 - val_loss: 0.9197\n",
      "Epoch 63/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6371 - loss: 0.6405 - val_accuracy: 0.1663 - val_loss: 0.9381\n",
      "Epoch 64/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6358 - loss: 0.6422 - val_accuracy: 0.1939 - val_loss: 0.9278\n",
      "Epoch 65/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6393 - loss: 0.6404 - val_accuracy: 0.1706 - val_loss: 0.9359\n",
      "Epoch 66/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6349 - loss: 0.6426 - val_accuracy: 0.1292 - val_loss: 0.9363\n",
      "Epoch 67/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6343 - loss: 0.6424 - val_accuracy: 0.1587 - val_loss: 0.9438\n",
      "Epoch 68/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6364 - loss: 0.6411 - val_accuracy: 0.1804 - val_loss: 0.9872\n",
      "Epoch 69/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6351 - loss: 0.6419 - val_accuracy: 0.1981 - val_loss: 0.9246\n",
      "Epoch 70/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - accuracy: 0.6375 - loss: 0.6412 - val_accuracy: 0.1698 - val_loss: 0.9334\n",
      "Epoch 71/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6358 - loss: 0.6417 - val_accuracy: 0.1727 - val_loss: 0.9502\n",
      "Epoch 72/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6376 - loss: 0.6416 - val_accuracy: 0.1866 - val_loss: 0.9103\n",
      "Epoch 73/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6370 - loss: 0.6411 - val_accuracy: 0.1762 - val_loss: 0.9396\n",
      "Epoch 74/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6364 - loss: 0.6423 - val_accuracy: 0.1543 - val_loss: 0.9872\n",
      "Epoch 75/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6345 - loss: 0.6424 - val_accuracy: 0.1509 - val_loss: 0.9598\n",
      "Epoch 76/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6380 - loss: 0.6395 - val_accuracy: 0.1962 - val_loss: 0.9223\n",
      "Epoch 77/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - accuracy: 0.6354 - loss: 0.6415 - val_accuracy: 0.2057 - val_loss: 0.9307\n",
      "Epoch 78/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 28ms/step - accuracy: 0.6366 - loss: 0.6421 - val_accuracy: 0.1713 - val_loss: 0.9980\n",
      "Epoch 79/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6350 - loss: 0.6427 - val_accuracy: 0.1318 - val_loss: 0.9799\n",
      "Epoch 80/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6387 - loss: 0.6408 - val_accuracy: 0.1663 - val_loss: 0.9299\n",
      "Epoch 81/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6342 - loss: 0.6418 - val_accuracy: 0.1672 - val_loss: 0.9432\n",
      "Epoch 82/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6384 - loss: 0.6404 - val_accuracy: 0.1701 - val_loss: 0.9643\n",
      "Epoch 83/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6379 - loss: 0.6413 - val_accuracy: 0.1560 - val_loss: 0.9538\n",
      "Epoch 84/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6365 - loss: 0.6421 - val_accuracy: 0.1563 - val_loss: 0.9511\n",
      "Epoch 85/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6381 - loss: 0.6403 - val_accuracy: 0.1467 - val_loss: 0.9701\n",
      "Epoch 86/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6327 - loss: 0.6425 - val_accuracy: 0.1052 - val_loss: 0.9866\n",
      "Epoch 87/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6368 - loss: 0.6414 - val_accuracy: 0.1820 - val_loss: 0.9185\n",
      "Epoch 88/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6382 - loss: 0.6409 - val_accuracy: 0.1820 - val_loss: 0.9269\n",
      "Epoch 89/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6352 - loss: 0.6421 - val_accuracy: 0.1621 - val_loss: 0.9321\n",
      "Epoch 90/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6363 - loss: 0.6414 - val_accuracy: 0.1325 - val_loss: 1.0059\n",
      "Epoch 91/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.6344 - loss: 0.6429 - val_accuracy: 0.1517 - val_loss: 0.9599\n",
      "Epoch 92/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - accuracy: 0.6358 - loss: 0.6415 - val_accuracy: 0.1791 - val_loss: 0.9545\n",
      "Epoch 93/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - accuracy: 0.6376 - loss: 0.6404 - val_accuracy: 0.1505 - val_loss: 0.9603\n",
      "Epoch 94/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6416 - val_accuracy: 0.1847 - val_loss: 0.9522\n",
      "Epoch 95/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - accuracy: 0.6380 - loss: 0.6408 - val_accuracy: 0.1957 - val_loss: 0.8957\n",
      "Epoch 96/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6376 - loss: 0.6410 - val_accuracy: 0.1803 - val_loss: 0.9398\n",
      "Epoch 97/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6384 - loss: 0.6403 - val_accuracy: 0.1611 - val_loss: 0.9235\n",
      "Epoch 98/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6377 - loss: 0.6401 - val_accuracy: 0.1437 - val_loss: 0.9691\n",
      "Epoch 99/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6350 - loss: 0.6421 - val_accuracy: 0.1522 - val_loss: 0.9570\n",
      "Epoch 100/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - accuracy: 0.6376 - loss: 0.6411 - val_accuracy: 0.1952 - val_loss: 0.9371\n",
      "Epoch 101/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6380 - loss: 0.6408 - val_accuracy: 0.1955 - val_loss: 0.9118\n",
      "Epoch 102/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6366 - loss: 0.6410 - val_accuracy: 0.1591 - val_loss: 0.9547\n",
      "Epoch 103/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6343 - loss: 0.6418 - val_accuracy: 0.1384 - val_loss: 0.9646\n",
      "Epoch 104/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6366 - loss: 0.6413 - val_accuracy: 0.1456 - val_loss: 0.9771\n",
      "Epoch 105/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - accuracy: 0.6335 - loss: 0.6425 - val_accuracy: 0.2472 - val_loss: 0.8752\n",
      "Epoch 106/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - accuracy: 0.6372 - loss: 0.6403 - val_accuracy: 0.1136 - val_loss: 1.0095\n",
      "Epoch 107/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6374 - loss: 0.6413 - val_accuracy: 0.1671 - val_loss: 0.9518\n",
      "Epoch 108/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6377 - loss: 0.6404 - val_accuracy: 0.1361 - val_loss: 0.9631\n",
      "Epoch 109/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.6342 - loss: 0.6424 - val_accuracy: 0.1351 - val_loss: 0.9822\n",
      "Epoch 110/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6412 - val_accuracy: 0.1666 - val_loss: 0.9514\n",
      "Epoch 111/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 41ms/step - accuracy: 0.6396 - loss: 0.6396 - val_accuracy: 0.1800 - val_loss: 0.9135\n",
      "Epoch 112/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 46ms/step - accuracy: 0.6375 - loss: 0.6413 - val_accuracy: 0.2104 - val_loss: 0.9295\n",
      "Epoch 113/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - accuracy: 0.6367 - loss: 0.6406 - val_accuracy: 0.1828 - val_loss: 0.9574\n",
      "Epoch 114/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - accuracy: 0.6382 - loss: 0.6413 - val_accuracy: 0.2106 - val_loss: 0.9118\n",
      "Epoch 115/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6378 - loss: 0.6406 - val_accuracy: 0.1653 - val_loss: 0.9423\n",
      "Epoch 116/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6365 - loss: 0.6412 - val_accuracy: 0.1620 - val_loss: 0.9482\n",
      "Epoch 117/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6377 - loss: 0.6420 - val_accuracy: 0.1498 - val_loss: 0.9902\n",
      "Epoch 118/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6365 - loss: 0.6413 - val_accuracy: 0.1614 - val_loss: 0.9206\n",
      "Epoch 119/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6392 - loss: 0.6397 - val_accuracy: 0.1716 - val_loss: 0.9560\n",
      "Epoch 120/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6357 - loss: 0.6420 - val_accuracy: 0.1657 - val_loss: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Imputando valores faltantes para a coluna 'Temp. Ins. (C)' em df3\n",
    "df3['Temp. Ins. (C)'] = df3['Temp. Ins. (C)'].fillna(df3['Temp. Ins. (C)'].mean())\n",
    "\n",
    "# Concatenando os DataFrames\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# Transformando a coluna 'num_ocorrencias' em binária (0: não ocorreu, 1: ocorreu)\n",
    "df['num_ocorrencias'] = df['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# Separando a variável alvo\n",
    "y = df['num_ocorrencias']\n",
    "\n",
    "# Definindo as features (X), excluindo a coluna alvo\n",
    "X = df.drop(columns=['num_ocorrencias'])\n",
    "\n",
    "# Normalizando os dados \n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Separando em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializando o SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "# Aplicando o SMOTE nos dados de treino\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificando a quantidade de amostras após o SMOTE\n",
    "print(f'Antes do SMOTE: {len(y_train[y_train == 1])} quedas de energia.')\n",
    "print(f'Depois do SMOTE: {len(y_resampled[y_resampled == 1])} quedas de energia.')\n",
    "\n",
    "# Modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1), y_resampled, epochs=120, batch_size=100, validation_split=0.2)\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_erro.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote_Previsao_3cvs_2019-2023_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_resampled: (147186, 4)\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.6286 - loss: 0.6570 - val_accuracy: 0.0868 - val_loss: 0.9375\n",
      "Epoch 2/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6316 - loss: 0.6487 - val_accuracy: 0.0719 - val_loss: 0.9655\n",
      "Epoch 3/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - accuracy: 0.6343 - loss: 0.6468 - val_accuracy: 0.1139 - val_loss: 0.9961\n",
      "Epoch 4/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.6331 - loss: 0.6465 - val_accuracy: 0.0711 - val_loss: 1.0658\n",
      "Epoch 5/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6323 - loss: 0.6465 - val_accuracy: 0.1274 - val_loss: 0.9456\n",
      "Epoch 6/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6341 - loss: 0.6459 - val_accuracy: 0.1028 - val_loss: 0.9808\n",
      "Epoch 7/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6304 - loss: 0.6483 - val_accuracy: 0.1160 - val_loss: 1.0345\n",
      "Epoch 8/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6321 - loss: 0.6464 - val_accuracy: 0.1188 - val_loss: 0.9872\n",
      "Epoch 9/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 21ms/step - accuracy: 0.6352 - loss: 0.6445 - val_accuracy: 0.1490 - val_loss: 0.9416\n",
      "Epoch 10/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6345 - loss: 0.6452 - val_accuracy: 0.2287 - val_loss: 0.9012\n",
      "Epoch 11/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - accuracy: 0.6334 - loss: 0.6457 - val_accuracy: 0.1445 - val_loss: 0.9591\n",
      "Epoch 12/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6331 - loss: 0.6448 - val_accuracy: 0.1165 - val_loss: 0.9696\n",
      "Epoch 13/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6352 - loss: 0.6433 - val_accuracy: 0.2392 - val_loss: 0.8798\n",
      "Epoch 14/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.6326 - loss: 0.6454 - val_accuracy: 0.1942 - val_loss: 0.9336\n",
      "Epoch 15/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6363 - loss: 0.6422 - val_accuracy: 0.1144 - val_loss: 0.9755\n",
      "Epoch 16/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6325 - loss: 0.6451 - val_accuracy: 0.0874 - val_loss: 1.0258\n",
      "Epoch 17/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6329 - loss: 0.6448 - val_accuracy: 0.0847 - val_loss: 0.9691\n",
      "Epoch 18/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6356 - loss: 0.6429 - val_accuracy: 0.1074 - val_loss: 1.0036\n",
      "Epoch 19/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6338 - loss: 0.6440 - val_accuracy: 0.2339 - val_loss: 0.8908\n",
      "Epoch 20/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6342 - loss: 0.6435 - val_accuracy: 0.1618 - val_loss: 0.9592\n",
      "Epoch 21/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - accuracy: 0.6328 - loss: 0.6444 - val_accuracy: 0.1703 - val_loss: 0.9527\n",
      "Epoch 22/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6309 - loss: 0.6446 - val_accuracy: 0.2040 - val_loss: 0.8977\n",
      "Epoch 23/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6332 - loss: 0.6447 - val_accuracy: 0.2854 - val_loss: 0.8844\n",
      "Epoch 24/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6362 - loss: 0.6421 - val_accuracy: 0.1447 - val_loss: 0.9961\n",
      "Epoch 25/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6333 - loss: 0.6443 - val_accuracy: 0.1170 - val_loss: 0.9691\n",
      "Epoch 26/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6359 - loss: 0.6428 - val_accuracy: 0.1403 - val_loss: 0.9518\n",
      "Epoch 27/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6347 - loss: 0.6428 - val_accuracy: 0.1486 - val_loss: 0.9750\n",
      "Epoch 28/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16ms/step - accuracy: 0.6363 - loss: 0.6424 - val_accuracy: 0.1706 - val_loss: 0.9490\n",
      "Epoch 29/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6319 - loss: 0.6452 - val_accuracy: 0.2108 - val_loss: 0.8828\n",
      "Epoch 30/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6382 - loss: 0.6416 - val_accuracy: 0.1394 - val_loss: 0.9700\n",
      "Epoch 31/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6324 - loss: 0.6445 - val_accuracy: 0.1812 - val_loss: 0.9536\n",
      "Epoch 32/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6350 - loss: 0.6435 - val_accuracy: 0.1387 - val_loss: 0.9720\n",
      "Epoch 33/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6355 - loss: 0.6437 - val_accuracy: 0.1560 - val_loss: 0.9355\n",
      "Epoch 34/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6346 - loss: 0.6427 - val_accuracy: 0.1771 - val_loss: 0.9725\n",
      "Epoch 35/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6327 - loss: 0.6441 - val_accuracy: 0.1917 - val_loss: 0.9218\n",
      "Epoch 36/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6343 - loss: 0.6433 - val_accuracy: 0.1398 - val_loss: 0.9727\n",
      "Epoch 37/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6353 - loss: 0.6434 - val_accuracy: 0.1399 - val_loss: 0.9222\n",
      "Epoch 38/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6368 - loss: 0.6417 - val_accuracy: 0.1616 - val_loss: 0.9562\n",
      "Epoch 39/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6344 - loss: 0.6431 - val_accuracy: 0.1995 - val_loss: 0.8901\n",
      "Epoch 40/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6333 - loss: 0.6443 - val_accuracy: 0.1472 - val_loss: 0.9664\n",
      "Epoch 41/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6315 - loss: 0.6444 - val_accuracy: 0.1195 - val_loss: 0.9887\n",
      "Epoch 42/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6339 - loss: 0.6428 - val_accuracy: 0.1741 - val_loss: 0.9182\n",
      "Epoch 43/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6343 - loss: 0.6428 - val_accuracy: 0.1296 - val_loss: 0.9778\n",
      "Epoch 44/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6354 - loss: 0.6424 - val_accuracy: 0.1168 - val_loss: 0.9793\n",
      "Epoch 45/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - accuracy: 0.6351 - loss: 0.6426 - val_accuracy: 0.1480 - val_loss: 0.9468\n",
      "Epoch 46/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.6355 - loss: 0.6418 - val_accuracy: 0.1369 - val_loss: 0.9797\n",
      "Epoch 47/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6362 - loss: 0.6425 - val_accuracy: 0.1168 - val_loss: 0.9843\n",
      "Epoch 48/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6351 - loss: 0.6419 - val_accuracy: 0.1462 - val_loss: 0.9513\n",
      "Epoch 49/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6402 - loss: 0.6397 - val_accuracy: 0.2231 - val_loss: 0.9005\n",
      "Epoch 50/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6378 - loss: 0.6406 - val_accuracy: 0.1346 - val_loss: 1.0030\n",
      "Epoch 51/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6349 - loss: 0.6432 - val_accuracy: 0.2639 - val_loss: 0.8682\n",
      "Epoch 52/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6343 - loss: 0.6430 - val_accuracy: 0.1257 - val_loss: 0.9538\n",
      "Epoch 53/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6362 - loss: 0.6414 - val_accuracy: 0.1174 - val_loss: 0.9909\n",
      "Epoch 54/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6364 - loss: 0.6416 - val_accuracy: 0.1712 - val_loss: 0.9725\n",
      "Epoch 55/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6357 - loss: 0.6415 - val_accuracy: 0.1969 - val_loss: 0.8970\n",
      "Epoch 56/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6360 - loss: 0.6417 - val_accuracy: 0.1638 - val_loss: 0.9063\n",
      "Epoch 57/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6373 - loss: 0.6421 - val_accuracy: 0.2354 - val_loss: 0.9120\n",
      "Epoch 58/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6353 - loss: 0.6427 - val_accuracy: 0.1573 - val_loss: 0.9711\n",
      "Epoch 59/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.6351 - loss: 0.6422 - val_accuracy: 0.1782 - val_loss: 0.9697\n",
      "Epoch 60/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6348 - loss: 0.6434 - val_accuracy: 0.1619 - val_loss: 0.9406\n",
      "Epoch 61/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6358 - loss: 0.6420 - val_accuracy: 0.1473 - val_loss: 0.9594\n",
      "Epoch 62/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6381 - loss: 0.6402 - val_accuracy: 0.1746 - val_loss: 0.9543\n",
      "Epoch 63/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6350 - loss: 0.6428 - val_accuracy: 0.1540 - val_loss: 0.9516\n",
      "Epoch 64/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6375 - loss: 0.6411 - val_accuracy: 0.1642 - val_loss: 0.9311\n",
      "Epoch 65/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - accuracy: 0.6364 - loss: 0.6427 - val_accuracy: 0.2057 - val_loss: 0.9176\n",
      "Epoch 66/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.6348 - loss: 0.6425 - val_accuracy: 0.2467 - val_loss: 0.9019\n",
      "Epoch 67/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16ms/step - accuracy: 0.6337 - loss: 0.6431 - val_accuracy: 0.1884 - val_loss: 0.9312\n",
      "Epoch 68/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6351 - loss: 0.6428 - val_accuracy: 0.2034 - val_loss: 0.9492\n",
      "Epoch 69/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6353 - loss: 0.6419 - val_accuracy: 0.1844 - val_loss: 0.9693\n",
      "Epoch 70/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6368 - loss: 0.6429 - val_accuracy: 0.1665 - val_loss: 0.9356\n",
      "Epoch 71/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6371 - loss: 0.6414 - val_accuracy: 0.1339 - val_loss: 0.9946\n",
      "Epoch 72/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6383 - loss: 0.6404 - val_accuracy: 0.1511 - val_loss: 0.9257\n",
      "Epoch 73/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6364 - loss: 0.6421 - val_accuracy: 0.1265 - val_loss: 0.9721\n",
      "Epoch 74/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - accuracy: 0.6372 - loss: 0.6409 - val_accuracy: 0.1758 - val_loss: 0.9549\n",
      "Epoch 75/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - accuracy: 0.6346 - loss: 0.6428 - val_accuracy: 0.1787 - val_loss: 0.9385\n",
      "Epoch 76/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 41ms/step - accuracy: 0.6359 - loss: 0.6418 - val_accuracy: 0.1890 - val_loss: 0.9288\n",
      "Epoch 77/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6417 - val_accuracy: 0.1380 - val_loss: 0.9486\n",
      "Epoch 78/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6370 - loss: 0.6423 - val_accuracy: 0.1195 - val_loss: 0.9396\n",
      "Epoch 79/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - accuracy: 0.6392 - loss: 0.6394 - val_accuracy: 0.1724 - val_loss: 0.9167\n",
      "Epoch 80/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - accuracy: 0.6399 - loss: 0.6401 - val_accuracy: 0.1476 - val_loss: 0.9405\n",
      "Epoch 81/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 31ms/step - accuracy: 0.6337 - loss: 0.6433 - val_accuracy: 0.1117 - val_loss: 0.9583\n",
      "Epoch 82/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.6354 - loss: 0.6431 - val_accuracy: 0.1558 - val_loss: 0.9600\n",
      "Epoch 83/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.6381 - loss: 0.6406 - val_accuracy: 0.1182 - val_loss: 0.9661\n",
      "Epoch 84/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.6357 - loss: 0.6419 - val_accuracy: 0.1330 - val_loss: 0.9789\n",
      "Epoch 85/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6372 - loss: 0.6412 - val_accuracy: 0.1733 - val_loss: 0.9774\n",
      "Epoch 86/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.6365 - loss: 0.6421 - val_accuracy: 0.1350 - val_loss: 0.9272\n",
      "Epoch 87/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6349 - loss: 0.6417 - val_accuracy: 0.1576 - val_loss: 0.9333\n",
      "Epoch 88/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6379 - loss: 0.6411 - val_accuracy: 0.1257 - val_loss: 1.0013\n",
      "Epoch 89/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6373 - loss: 0.6416 - val_accuracy: 0.1793 - val_loss: 0.9630\n",
      "Epoch 90/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.6365 - loss: 0.6427 - val_accuracy: 0.1717 - val_loss: 0.9687\n",
      "Epoch 91/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6345 - loss: 0.6430 - val_accuracy: 0.1879 - val_loss: 0.9671\n",
      "Epoch 92/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.6366 - loss: 0.6422 - val_accuracy: 0.1433 - val_loss: 0.9659\n",
      "Epoch 93/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6381 - loss: 0.6400 - val_accuracy: 0.1454 - val_loss: 0.9648\n",
      "Epoch 94/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.6361 - loss: 0.6418 - val_accuracy: 0.1545 - val_loss: 0.9653\n",
      "Epoch 95/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6357 - loss: 0.6422 - val_accuracy: 0.1264 - val_loss: 0.9866\n",
      "Epoch 96/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.6384 - loss: 0.6413 - val_accuracy: 0.1892 - val_loss: 0.9644\n",
      "Epoch 97/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6371 - loss: 0.6419 - val_accuracy: 0.1947 - val_loss: 0.9434\n",
      "Epoch 98/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.6357 - loss: 0.6416 - val_accuracy: 0.1547 - val_loss: 0.9603\n",
      "Epoch 99/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.6347 - loss: 0.6424 - val_accuracy: 0.1480 - val_loss: 0.9555\n",
      "Epoch 100/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.6365 - loss: 0.6416 - val_accuracy: 0.1639 - val_loss: 0.9396\n",
      "Epoch 101/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - accuracy: 0.6355 - loss: 0.6424 - val_accuracy: 0.1752 - val_loss: 0.9265\n",
      "Epoch 102/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - accuracy: 0.6349 - loss: 0.6421 - val_accuracy: 0.2079 - val_loss: 0.9261\n",
      "Epoch 103/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 28ms/step - accuracy: 0.6387 - loss: 0.6402 - val_accuracy: 0.1400 - val_loss: 0.9536\n",
      "Epoch 104/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.6387 - loss: 0.6403 - val_accuracy: 0.1977 - val_loss: 0.9242\n",
      "Epoch 105/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - accuracy: 0.6341 - loss: 0.6431 - val_accuracy: 0.1617 - val_loss: 0.9566\n",
      "Epoch 106/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 35ms/step - accuracy: 0.6349 - loss: 0.6421 - val_accuracy: 0.1749 - val_loss: 0.9625\n",
      "Epoch 107/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.6360 - loss: 0.6419 - val_accuracy: 0.2100 - val_loss: 0.9066\n",
      "Epoch 108/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36ms/step - accuracy: 0.6387 - loss: 0.6402 - val_accuracy: 0.1412 - val_loss: 0.9540\n",
      "Epoch 109/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - accuracy: 0.6373 - loss: 0.6415 - val_accuracy: 0.1574 - val_loss: 0.9278\n",
      "Epoch 110/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - accuracy: 0.6374 - loss: 0.6408 - val_accuracy: 0.1234 - val_loss: 0.9918\n",
      "Epoch 111/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.6366 - loss: 0.6418 - val_accuracy: 0.1784 - val_loss: 0.9288\n",
      "Epoch 112/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - accuracy: 0.6370 - loss: 0.6416 - val_accuracy: 0.1289 - val_loss: 0.9606\n",
      "Epoch 113/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.6368 - loss: 0.6417 - val_accuracy: 0.1831 - val_loss: 0.9311\n",
      "Epoch 114/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - accuracy: 0.6348 - loss: 0.6427 - val_accuracy: 0.1286 - val_loss: 0.9474\n",
      "Epoch 115/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6353 - loss: 0.6425 - val_accuracy: 0.1164 - val_loss: 0.9810\n",
      "Epoch 116/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6351 - loss: 0.6432 - val_accuracy: 0.1440 - val_loss: 0.9751\n",
      "Epoch 117/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6410 - loss: 0.6399 - val_accuracy: 0.2025 - val_loss: 0.9039\n",
      "Epoch 118/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.6376 - loss: 0.6409 - val_accuracy: 0.1940 - val_loss: 0.9261\n",
      "Epoch 119/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.6400 - loss: 0.6391 - val_accuracy: 0.1935 - val_loss: 0.9512\n",
      "Epoch 120/120\n",
      "\u001b[1m1178/1178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.6357 - loss: 0.6419 - val_accuracy: 0.1149 - val_loss: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m805/805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Acurácia: 0.7098\n",
      "Sensibilidade (Recall): 0.1196\n",
      "AUC: 0.5346\n",
      "Especificidade: 0.9496\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar e preparar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Concatenar os DataFrames\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df['num_ocorrencias'] = df['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y = df['num_ocorrencias']\n",
    "X = df.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes (preenchendo com a média das colunas, por exemplo)\n",
    "imputer = SimpleImputer(strategy='mean')  # Você pode alterar para 'median' ou outro método\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar SMOTE para balanceamento\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificar a forma de X_resampled\n",
    "print(f\"Forma de X_resampled: {X_resampled.shape}\")  # Deve ser (n amostras, n_features)\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo, ajustando o reshape para incluir o terceiro eixo (n_features=1)\n",
    "model.fit(\n",
    "    X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1),  # reshape para (amostras, features, 1)\n",
    "    y_resampled,\n",
    "    epochs=120,\n",
    "    batch_size=100,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v1.h5')\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo concatenaçao df1 e df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_resampled: (133356, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.6247 - loss: 0.6597 - val_accuracy: 0.0778 - val_loss: 1.0071\n",
      "Epoch 2/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - accuracy: 0.6256 - loss: 0.6522 - val_accuracy: 0.0603 - val_loss: 0.9953\n",
      "Epoch 3/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.6278 - loss: 0.6519 - val_accuracy: 0.0902 - val_loss: 1.0027\n",
      "Epoch 4/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - accuracy: 0.6256 - loss: 0.6519 - val_accuracy: 0.0324 - val_loss: 0.9810\n",
      "Epoch 5/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 26ms/step - accuracy: 0.6296 - loss: 0.6497 - val_accuracy: 0.0842 - val_loss: 0.9378\n",
      "Epoch 6/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 26ms/step - accuracy: 0.6281 - loss: 0.6508 - val_accuracy: 0.1273 - val_loss: 0.9323\n",
      "Epoch 7/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.6298 - loss: 0.6500 - val_accuracy: 0.0788 - val_loss: 0.9728\n",
      "Epoch 8/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - accuracy: 0.6311 - loss: 0.6488 - val_accuracy: 0.0351 - val_loss: 1.0690\n",
      "Epoch 9/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 31ms/step - accuracy: 0.6304 - loss: 0.6489 - val_accuracy: 0.1787 - val_loss: 0.8941\n",
      "Epoch 10/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 30ms/step - accuracy: 0.6318 - loss: 0.6484 - val_accuracy: 0.1012 - val_loss: 0.9912\n",
      "Epoch 11/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.6301 - loss: 0.6483 - val_accuracy: 0.1379 - val_loss: 0.9804\n",
      "Epoch 12/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - accuracy: 0.6311 - loss: 0.6477 - val_accuracy: 0.1131 - val_loss: 0.9751\n",
      "Epoch 13/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 26ms/step - accuracy: 0.6342 - loss: 0.6462 - val_accuracy: 0.2253 - val_loss: 0.8752\n",
      "Epoch 14/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 27ms/step - accuracy: 0.6319 - loss: 0.6467 - val_accuracy: 0.1436 - val_loss: 0.9536\n",
      "Epoch 15/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.6317 - loss: 0.6465 - val_accuracy: 0.1433 - val_loss: 0.9599\n",
      "Epoch 16/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - accuracy: 0.6353 - loss: 0.6454 - val_accuracy: 0.0942 - val_loss: 1.0019\n",
      "Epoch 17/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 27ms/step - accuracy: 0.6342 - loss: 0.6458 - val_accuracy: 0.1441 - val_loss: 0.9661\n",
      "Epoch 18/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 27ms/step - accuracy: 0.6314 - loss: 0.6470 - val_accuracy: 0.1076 - val_loss: 0.9805\n",
      "Epoch 19/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.6310 - loss: 0.6478 - val_accuracy: 0.1466 - val_loss: 0.9336\n",
      "Epoch 20/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - accuracy: 0.6329 - loss: 0.6459 - val_accuracy: 0.1283 - val_loss: 0.9690\n",
      "Epoch 21/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.6337 - loss: 0.6450 - val_accuracy: 0.1340 - val_loss: 0.9273\n",
      "Epoch 22/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - accuracy: 0.6308 - loss: 0.6458 - val_accuracy: 0.1037 - val_loss: 1.0137\n",
      "Epoch 23/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - accuracy: 0.6329 - loss: 0.6454 - val_accuracy: 0.1320 - val_loss: 0.9790\n",
      "Epoch 24/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.6316 - loss: 0.6465 - val_accuracy: 0.1260 - val_loss: 0.9434\n",
      "Epoch 25/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.6322 - loss: 0.6462 - val_accuracy: 0.1016 - val_loss: 0.9596\n",
      "Epoch 26/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.6331 - loss: 0.6464 - val_accuracy: 0.1421 - val_loss: 0.9772\n",
      "Epoch 27/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.6306 - loss: 0.6463 - val_accuracy: 0.1223 - val_loss: 0.9623\n",
      "Epoch 28/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.6325 - loss: 0.6465 - val_accuracy: 0.1820 - val_loss: 0.9334\n",
      "Epoch 29/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.6323 - loss: 0.6453 - val_accuracy: 0.0953 - val_loss: 0.9617\n",
      "Epoch 30/30\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - accuracy: 0.6316 - loss: 0.6466 - val_accuracy: 0.1214 - val_loss: 0.9697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step\n",
      "Acurácia: 0.6060\n",
      "Sensibilidade (Recall): 0.1864\n",
      "AUC: 0.5405\n",
      "Especificidade: 0.8947\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar e preparar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Concatenar os DataFrames df1 e df2 para treinamento\n",
    "df_train = pd.concat([df1, df2])\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df_train['num_ocorrencias'] = df_train['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df_train['num_ocorrencias']\n",
    "X_train = df_train.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes (preenchendo com a média das colunas, por exemplo)\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar SMOTE para balanceamento\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Verificar a forma de X_resampled\n",
    "print(f\"Forma de X_resampled: {X_resampled.shape}\")  # Deve ser (n amostras, n_features)\n",
    "\n",
    "# Preparar o conjunto de teste\n",
    "df_test = df3.copy()\n",
    "df_test['num_ocorrencias'] = df_test['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df_test['num_ocorrencias']\n",
    "X_test = df_test.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes e escalar os dados de teste\n",
    "X_test = imputer.transform(X_test)  # Usar o mesmo imputer\n",
    "X_test_scaled = scaler.transform(X_test)  # Usar o mesmo scaler\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo, ajustando o reshape para incluir o terceiro eixo (n_features=1)\n",
    "model.fit(\n",
    "    X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1),  # reshape para (amostras, features, 1)\n",
    "    y_resampled,\n",
    "    epochs=30,  # Reduzir o número de epochs\n",
    "    batch_size=100,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v2.h5')\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Smote_Previsao_3cvs_2019-2023_v3.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_resampled: (133356, 4)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.6299 - loss: 0.6547 - val_accuracy: 0.0118 - val_loss: 1.0110\n",
      "Epoch 2/50\n",
      "\u001b[1m   8/1667\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.6199 - loss: 0.6577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_auc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 27ms/step - accuracy: 0.6325 - loss: 0.6487 - val_accuracy: 0.1063 - val_loss: 0.9455\n",
      "Epoch 3/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.6323 - loss: 0.6467 - val_accuracy: 0.1906 - val_loss: 0.9038\n",
      "Epoch 4/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.6302 - loss: 0.6473 - val_accuracy: 0.1733 - val_loss: 0.9005\n",
      "Epoch 5/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - accuracy: 0.6356 - loss: 0.6448 - val_accuracy: 0.1452 - val_loss: 0.9216\n",
      "Epoch 6/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.6300 - loss: 0.6474 - val_accuracy: 0.1437 - val_loss: 0.9421\n",
      "Epoch 7/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.6333 - loss: 0.6461 - val_accuracy: 0.1496 - val_loss: 0.9166\n",
      "Epoch 8/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.6319 - loss: 0.6465 - val_accuracy: 0.0893 - val_loss: 1.0252\n",
      "Epoch 9/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.6328 - loss: 0.6460 - val_accuracy: 0.1020 - val_loss: 0.9603\n",
      "Epoch 10/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 43ms/step - accuracy: 0.6310 - loss: 0.6458 - val_accuracy: 0.1456 - val_loss: 0.9609\n",
      "Epoch 11/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 48ms/step - accuracy: 0.6315 - loss: 0.6455 - val_accuracy: 0.1867 - val_loss: 0.9355\n",
      "Epoch 12/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.6321 - loss: 0.6465 - val_accuracy: 0.1848 - val_loss: 0.8756\n",
      "Epoch 13/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.6335 - loss: 0.6443 - val_accuracy: 0.1439 - val_loss: 0.9243\n",
      "Epoch 14/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.6338 - loss: 0.6449 - val_accuracy: 0.0982 - val_loss: 0.9545\n",
      "Epoch 15/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.6339 - loss: 0.6452 - val_accuracy: 0.2137 - val_loss: 0.9249\n",
      "Epoch 16/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.6348 - loss: 0.6442 - val_accuracy: 0.1279 - val_loss: 1.0135\n",
      "Epoch 17/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.6350 - loss: 0.6442 - val_accuracy: 0.0954 - val_loss: 0.9720\n",
      "Epoch 18/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.6346 - loss: 0.6451 - val_accuracy: 0.1085 - val_loss: 0.9651\n",
      "Epoch 19/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.6350 - loss: 0.6447 - val_accuracy: 0.1353 - val_loss: 0.9684\n",
      "Epoch 20/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 21ms/step - accuracy: 0.6333 - loss: 0.6453 - val_accuracy: 0.1518 - val_loss: 0.9485\n",
      "Epoch 21/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.6346 - loss: 0.6442 - val_accuracy: 0.0958 - val_loss: 0.9429\n",
      "Epoch 22/50\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.6341 - loss: 0.6453 - val_accuracy: 0.1286 - val_loss: 0.9815\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
      "Acurácia: 0.6065\n",
      "Sensibilidade (Recall): 0.2703\n",
      "AUC: 0.5540\n",
      "Especificidade: 0.8378\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Carregar e preparar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Concatenar os DataFrames para treino (usando df1 e df2)\n",
    "df_train = pd.concat([df1, df2])\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df_train['num_ocorrencias'] = df_train['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df_train['num_ocorrencias']\n",
    "X_train = df_train.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes (preenchendo com a média das colunas)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar SMOTE para balanceamento\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Preparar os dados de teste\n",
    "df_test = df3.copy()\n",
    "df_test['num_ocorrencias'] = df_test['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df_test['num_ocorrencias']\n",
    "X_test = df_test.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar e escalar os dados de teste\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verificar a forma de X_resampled\n",
    "print(f\"Forma de X_resampled: {X_resampled.shape}\")\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=150, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=150, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Configurar callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1),\n",
    "    y_resampled,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v3.h5')\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote_Previsao_3cvs_2019-2023_v4.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 36ms/step - accuracy: 0.6262 - loss: 0.6564 - val_accuracy: 0.0546 - val_loss: 1.0032\n",
      "Epoch 2/100\n",
      "\u001b[1m   7/1667\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.6264 - loss: 0.6599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_auc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 37ms/step - accuracy: 0.6310 - loss: 0.6475 - val_accuracy: 0.1308 - val_loss: 0.9109\n",
      "Epoch 3/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 41ms/step - accuracy: 0.6316 - loss: 0.6479 - val_accuracy: 0.0612 - val_loss: 1.0183\n",
      "Epoch 4/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 38ms/step - accuracy: 0.6344 - loss: 0.6461 - val_accuracy: 0.0851 - val_loss: 0.9673\n",
      "Epoch 5/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 42ms/step - accuracy: 0.6327 - loss: 0.6471 - val_accuracy: 0.0841 - val_loss: 0.9386\n",
      "Epoch 6/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 39ms/step - accuracy: 0.6310 - loss: 0.6474 - val_accuracy: 0.1349 - val_loss: 1.0292\n",
      "Epoch 7/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 40ms/step - accuracy: 0.6317 - loss: 0.6457 - val_accuracy: 0.0992 - val_loss: 0.9776\n",
      "Epoch 8/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 43ms/step - accuracy: 0.6327 - loss: 0.6455 - val_accuracy: 0.0420 - val_loss: 1.0349\n",
      "Epoch 9/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 39ms/step - accuracy: 0.6327 - loss: 0.6459 - val_accuracy: 0.2093 - val_loss: 0.9076\n",
      "Epoch 10/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 37ms/step - accuracy: 0.6313 - loss: 0.6474 - val_accuracy: 0.2900 - val_loss: 0.8606\n",
      "Epoch 11/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 31ms/step - accuracy: 0.6324 - loss: 0.6453 - val_accuracy: 0.0709 - val_loss: 0.9994\n",
      "Epoch 12/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.6340 - loss: 0.6445 - val_accuracy: 0.1476 - val_loss: 0.9295\n",
      "Epoch 13/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.6330 - loss: 0.6452 - val_accuracy: 0.1232 - val_loss: 0.9838\n",
      "Epoch 14/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6458 - val_accuracy: 0.1623 - val_loss: 0.9324\n",
      "Epoch 15/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 38ms/step - accuracy: 0.6302 - loss: 0.6468 - val_accuracy: 0.2047 - val_loss: 0.9585\n",
      "Epoch 16/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 44ms/step - accuracy: 0.6320 - loss: 0.6455 - val_accuracy: 0.1276 - val_loss: 0.9227\n",
      "Epoch 17/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 32ms/step - accuracy: 0.6335 - loss: 0.6453 - val_accuracy: 0.1054 - val_loss: 0.9568\n",
      "Epoch 18/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 37ms/step - accuracy: 0.6310 - loss: 0.6456 - val_accuracy: 0.1224 - val_loss: 0.9824\n",
      "Epoch 19/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 52ms/step - accuracy: 0.6342 - loss: 0.6442 - val_accuracy: 0.1596 - val_loss: 0.9432\n",
      "Epoch 20/100\n",
      "\u001b[1m1667/1667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 78ms/step - accuracy: 0.6356 - loss: 0.6436 - val_accuracy: 0.0795 - val_loss: 1.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step\n",
      "Acurácia: 0.5938\n",
      "Sensibilidade (Recall): 0.3884\n",
      "AUC: 0.5617\n",
      "Especificidade: 0.7351\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Carregar e preparar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Concatenar os DataFrames para treino (usando df1 e df2)\n",
    "df_train = pd.concat([df1, df2])\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df_train['num_ocorrencias'] = df_train['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df_train['num_ocorrencias']\n",
    "X_train = df_train.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar SMOTE para balanceamento\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Preparar os dados de teste\n",
    "df_test = df3.copy()\n",
    "df_test['num_ocorrencias'] = df_test['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df_test['num_ocorrencias']\n",
    "X_test = df_test.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar e escalar os dados de teste\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=150, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.3))  # Aumentar taxa de dropout\n",
    "model.add(LSTM(units=150, return_sequences=True))  # Adicionar outra camada LSTM\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=150, return_sequences=False))  # Última camada LSTM\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Configurar callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled.reshape(X_resampled.shape[0], X_resampled.shape[1], 1),\n",
    "    y_resampled,\n",
    "    epochs=100,  # Aumentar número de épocas\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v4.h5')\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EROO: Smote_Previsao_3cvs_2019-2023_v5.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.6249 - loss: 0.6627 - val_accuracy: 0.1470 - val_loss: 0.9360\n",
      "Epoch 2/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6248 - loss: 0.6497 - val_accuracy: 0.0428 - val_loss: 1.0841\n",
      "Epoch 3/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6330 - loss: 0.6450 - val_accuracy: 0.0536 - val_loss: 1.0515\n",
      "Epoch 4/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6307 - loss: 0.6464 - val_accuracy: 0.1445 - val_loss: 1.0172\n",
      "Epoch 5/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6327 - loss: 0.6443 - val_accuracy: 0.0979 - val_loss: 1.1059\n",
      "Epoch 6/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.6410 - loss: 0.6429 - val_accuracy: 0.0422 - val_loss: 1.1706\n",
      "Epoch 7/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6340 - loss: 0.6342 - val_accuracy: 4.2194e-04 - val_loss: 2.0208\n",
      "Epoch 8/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.6414 - loss: 0.6046 - val_accuracy: 0.1184 - val_loss: 3.8307\n",
      "Epoch 9/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6420 - loss: 0.5934 - val_accuracy: 0.1129 - val_loss: 4.7738\n",
      "Epoch 10/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6377 - loss: 0.5955 - val_accuracy: 0.0886 - val_loss: 6.0486\n",
      "Epoch 11/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.6494 - loss: 0.5882 - val_accuracy: 0.1268 - val_loss: 5.9743\n",
      "Epoch 12/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6429 - loss: 0.5896 - val_accuracy: 0.0534 - val_loss: 4.4734\n",
      "Epoch 13/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6394 - loss: 0.5928 - val_accuracy: 0.1181 - val_loss: 8.1809\n",
      "Epoch 14/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6443 - loss: 0.5861 - val_accuracy: 0.0882 - val_loss: 9.0819\n",
      "Epoch 15/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.6463 - loss: 0.5890 - val_accuracy: 0.0494 - val_loss: 8.8472\n",
      "Epoch 16/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.6430 - loss: 0.5884 - val_accuracy: 0.1207 - val_loss: 8.4411\n",
      "Epoch 17/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.6454 - loss: 0.5887 - val_accuracy: 0.0300 - val_loss: 9.1300\n",
      "Epoch 18/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6396 - loss: 0.5952 - val_accuracy: 0.0515 - val_loss: 7.7300\n",
      "Epoch 19/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.5913 - val_accuracy: 0.1325 - val_loss: 7.4249\n",
      "Epoch 20/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6387 - loss: 0.5921 - val_accuracy: 0.0899 - val_loss: 7.1902\n",
      "Epoch 21/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.6434 - loss: 0.5917 - val_accuracy: 0.0973 - val_loss: 8.2227\n",
      "Epoch 22/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.6400 - loss: 0.5887 - val_accuracy: 0.0905 - val_loss: 9.1092\n",
      "Epoch 23/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6414 - loss: 0.5886 - val_accuracy: 0.0850 - val_loss: 9.6434\n",
      "Epoch 24/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6482 - loss: 0.5845 - val_accuracy: 0.1008 - val_loss: 6.8857\n",
      "Epoch 25/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6387 - loss: 0.5917 - val_accuracy: 0.0637 - val_loss: 9.5219\n",
      "Epoch 26/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6405 - loss: 0.5925 - val_accuracy: 0.0926 - val_loss: 10.3641\n",
      "Epoch 27/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6468 - loss: 0.5897 - val_accuracy: 0.1171 - val_loss: 8.9116\n",
      "Epoch 28/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6415 - loss: 0.5896 - val_accuracy: 0.1150 - val_loss: 10.3645\n",
      "Epoch 29/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.5897 - val_accuracy: 0.0766 - val_loss: 9.1383\n",
      "Epoch 30/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6478 - loss: 0.5910 - val_accuracy: 0.0890 - val_loss: 7.9178\n",
      "Epoch 31/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6421 - loss: 0.5886 - val_accuracy: 0.0525 - val_loss: 8.1658\n",
      "Epoch 32/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6379 - loss: 0.5893 - val_accuracy: 0.1089 - val_loss: 8.5107\n",
      "Epoch 33/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6458 - loss: 0.5895 - val_accuracy: 0.1546 - val_loss: 9.3790\n",
      "Epoch 34/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6451 - loss: 0.5886 - val_accuracy: 0.1021 - val_loss: 7.8114\n",
      "Epoch 35/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6398 - loss: 0.5901 - val_accuracy: 0.1757 - val_loss: 6.7979\n",
      "Epoch 36/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6442 - loss: 0.5907 - val_accuracy: 0.1030 - val_loss: 8.1743\n",
      "Epoch 37/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6474 - loss: 0.5858 - val_accuracy: 0.0736 - val_loss: 9.1221\n",
      "Epoch 38/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6405 - loss: 0.5904 - val_accuracy: 0.0992 - val_loss: 8.6974\n",
      "Epoch 39/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6360 - loss: 0.5934 - val_accuracy: 0.1023 - val_loss: 8.8695\n",
      "Epoch 40/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6452 - loss: 0.5873 - val_accuracy: 0.0890 - val_loss: 5.8884\n",
      "Epoch 41/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6423 - loss: 0.5902 - val_accuracy: 0.1215 - val_loss: 7.8442\n",
      "Epoch 42/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6512 - loss: 0.5827 - val_accuracy: 0.0932 - val_loss: 7.0015\n",
      "Epoch 43/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6364 - loss: 0.5930 - val_accuracy: 0.0745 - val_loss: 8.1887\n",
      "Epoch 44/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6416 - loss: 0.5898 - val_accuracy: 0.1679 - val_loss: 7.8945\n",
      "Epoch 45/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6467 - loss: 0.5887 - val_accuracy: 0.0793 - val_loss: 6.9601\n",
      "Epoch 46/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.6423 - loss: 0.5914 - val_accuracy: 0.0998 - val_loss: 7.6384\n",
      "Epoch 47/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6418 - loss: 0.5889 - val_accuracy: 0.1481 - val_loss: 7.1121\n",
      "Epoch 48/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6441 - loss: 0.5895 - val_accuracy: 0.1114 - val_loss: 7.3600\n",
      "Epoch 49/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.6438 - loss: 0.5887 - val_accuracy: 0.0586 - val_loss: 6.6402\n",
      "Epoch 50/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6450 - loss: 0.5848 - val_accuracy: 0.1080 - val_loss: 6.8356\n",
      "Epoch 51/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6492 - loss: 0.5862 - val_accuracy: 0.0816 - val_loss: 7.4622\n",
      "Epoch 52/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6427 - loss: 0.5901 - val_accuracy: 0.0810 - val_loss: 8.1539\n",
      "Epoch 53/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6488 - loss: 0.5876 - val_accuracy: 0.0888 - val_loss: 7.4290\n",
      "Epoch 54/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6454 - loss: 0.5917 - val_accuracy: 0.1234 - val_loss: 6.6637\n",
      "Epoch 55/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6487 - loss: 0.5850 - val_accuracy: 0.0989 - val_loss: 6.9965\n",
      "Epoch 56/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6413 - loss: 0.5888 - val_accuracy: 0.0816 - val_loss: 6.3365\n",
      "Epoch 57/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6476 - loss: 0.5844 - val_accuracy: 0.0914 - val_loss: 6.5987\n",
      "Epoch 58/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6478 - loss: 0.5913 - val_accuracy: 0.0589 - val_loss: 6.4460\n",
      "Epoch 59/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.6454 - loss: 0.5875 - val_accuracy: 0.1169 - val_loss: 7.0409\n",
      "Epoch 60/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.6487 - loss: 0.5880 - val_accuracy: 0.0764 - val_loss: 5.5938\n",
      "Epoch 61/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6414 - loss: 0.5924 - val_accuracy: 0.0762 - val_loss: 6.2968\n",
      "Epoch 62/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6431 - loss: 0.5879 - val_accuracy: 0.1150 - val_loss: 6.2965\n",
      "Epoch 63/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6446 - loss: 0.5913 - val_accuracy: 0.0477 - val_loss: 6.3803\n",
      "Epoch 64/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6439 - loss: 0.5900 - val_accuracy: 0.1340 - val_loss: 6.3398\n",
      "Epoch 65/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.6470 - loss: 0.5895 - val_accuracy: 0.0956 - val_loss: 6.5168\n",
      "Epoch 66/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.6492 - loss: 0.5863 - val_accuracy: 0.1272 - val_loss: 6.5394\n",
      "Epoch 67/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6461 - loss: 0.5883 - val_accuracy: 0.1390 - val_loss: 6.3554\n",
      "Epoch 68/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6441 - loss: 0.5887 - val_accuracy: 0.1259 - val_loss: 6.0317\n",
      "Epoch 69/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6431 - loss: 0.5885 - val_accuracy: 0.1382 - val_loss: 5.6528\n",
      "Epoch 70/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6515 - loss: 0.5877 - val_accuracy: 0.0882 - val_loss: 5.9311\n",
      "Epoch 71/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6479 - loss: 0.5839 - val_accuracy: 0.0992 - val_loss: 5.0177\n",
      "Epoch 72/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.6556 - loss: 0.5815 - val_accuracy: 0.0620 - val_loss: 5.5332\n",
      "Epoch 73/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.6506 - loss: 0.5840 - val_accuracy: 0.0892 - val_loss: 6.0754\n",
      "Epoch 74/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6505 - loss: 0.5884 - val_accuracy: 0.0658 - val_loss: 6.3668\n",
      "Epoch 75/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6425 - loss: 0.5897 - val_accuracy: 0.0973 - val_loss: 5.1057\n",
      "Epoch 76/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6494 - loss: 0.5857 - val_accuracy: 0.0854 - val_loss: 6.0330\n",
      "Epoch 77/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6456 - loss: 0.5883 - val_accuracy: 0.1369 - val_loss: 5.8687\n",
      "Epoch 78/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6402 - loss: 0.5890 - val_accuracy: 0.1124 - val_loss: 6.1192\n",
      "Epoch 79/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.6438 - loss: 0.5861 - val_accuracy: 0.1340 - val_loss: 5.8649\n",
      "Epoch 80/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6477 - loss: 0.5846 - val_accuracy: 0.1074 - val_loss: 5.6282\n",
      "Epoch 81/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6467 - loss: 0.5866 - val_accuracy: 0.0996 - val_loss: 5.5813\n",
      "Epoch 82/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.6454 - loss: 0.5876 - val_accuracy: 0.1019 - val_loss: 6.2613\n",
      "Epoch 83/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6529 - loss: 0.5810 - val_accuracy: 0.0831 - val_loss: 6.6180\n",
      "Epoch 84/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6507 - loss: 0.5830 - val_accuracy: 0.1198 - val_loss: 6.4207\n",
      "Epoch 85/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6473 - loss: 0.5870 - val_accuracy: 0.1234 - val_loss: 6.8163\n",
      "Epoch 86/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6468 - loss: 0.5873 - val_accuracy: 0.1232 - val_loss: 7.1433\n",
      "Epoch 87/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6447 - loss: 0.5882 - val_accuracy: 0.0973 - val_loss: 6.6910\n",
      "Epoch 88/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6451 - loss: 0.5890 - val_accuracy: 0.0517 - val_loss: 6.3506\n",
      "Epoch 89/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6442 - loss: 0.5876 - val_accuracy: 0.0932 - val_loss: 6.3684\n",
      "Epoch 90/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6443 - loss: 0.5882 - val_accuracy: 0.0951 - val_loss: 6.1157\n",
      "Epoch 91/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.6523 - loss: 0.5835 - val_accuracy: 0.1169 - val_loss: 6.2328\n",
      "Epoch 92/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6444 - loss: 0.5895 - val_accuracy: 0.0873 - val_loss: 6.6903\n",
      "Epoch 93/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.6448 - loss: 0.5874 - val_accuracy: 0.0907 - val_loss: 7.0815\n",
      "Epoch 94/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.6478 - loss: 0.5874 - val_accuracy: 0.1359 - val_loss: 6.8004\n",
      "Epoch 95/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.6456 - loss: 0.5892 - val_accuracy: 0.0928 - val_loss: 6.8209\n",
      "Epoch 96/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.6467 - loss: 0.5872 - val_accuracy: 0.1049 - val_loss: 6.9258\n",
      "Epoch 97/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.6457 - loss: 0.5848 - val_accuracy: 0.0770 - val_loss: 6.7745\n",
      "Epoch 98/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6458 - loss: 0.5874 - val_accuracy: 0.1042 - val_loss: 6.3477\n",
      "Epoch 99/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.6440 - loss: 0.5863 - val_accuracy: 0.0890 - val_loss: 8.5527\n",
      "Epoch 100/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6512 - loss: 0.5879 - val_accuracy: 0.1063 - val_loss: 6.8100\n",
      "Epoch 101/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.6422 - loss: 0.5874 - val_accuracy: 0.0838 - val_loss: 7.8450\n",
      "Epoch 102/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.6455 - loss: 0.5872 - val_accuracy: 0.1011 - val_loss: 7.8449\n",
      "Epoch 103/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.6497 - loss: 0.5866 - val_accuracy: 0.0800 - val_loss: 7.9205\n",
      "Epoch 104/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.6454 - loss: 0.5879 - val_accuracy: 0.0939 - val_loss: 8.0715\n",
      "Epoch 105/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.6480 - loss: 0.5882 - val_accuracy: 0.1367 - val_loss: 7.1205\n",
      "Epoch 106/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.6446 - loss: 0.5870 - val_accuracy: 0.1264 - val_loss: 7.0438\n",
      "Epoch 107/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.6403 - loss: 0.5879 - val_accuracy: 0.0882 - val_loss: 6.8951\n",
      "Epoch 108/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.6465 - loss: 0.5866 - val_accuracy: 0.0759 - val_loss: 5.9873\n",
      "Epoch 109/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.6539 - loss: 0.5838 - val_accuracy: 0.0962 - val_loss: 7.1386\n",
      "Epoch 110/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.6418 - loss: 0.5879 - val_accuracy: 0.1352 - val_loss: 6.7700\n",
      "Epoch 111/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.6531 - loss: 0.5833 - val_accuracy: 0.1139 - val_loss: 6.1235\n",
      "Epoch 112/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6487 - loss: 0.5838 - val_accuracy: 0.0911 - val_loss: 6.6534\n",
      "Epoch 113/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6460 - loss: 0.5873 - val_accuracy: 0.0994 - val_loss: 6.6388\n",
      "Epoch 114/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.6473 - loss: 0.5868 - val_accuracy: 0.0764 - val_loss: 6.4359\n",
      "Epoch 115/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.6505 - loss: 0.5882 - val_accuracy: 0.0795 - val_loss: 6.4271\n",
      "Epoch 116/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.6438 - loss: 0.5863 - val_accuracy: 0.1055 - val_loss: 6.9684\n",
      "Epoch 117/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.6494 - loss: 0.5861 - val_accuracy: 0.1120 - val_loss: 6.5840\n",
      "Epoch 118/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.6358 - loss: 0.5914 - val_accuracy: 0.1264 - val_loss: 6.4337\n",
      "Epoch 119/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.6424 - loss: 0.5881 - val_accuracy: 0.1209 - val_loss: 6.5311\n",
      "Epoch 120/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - accuracy: 0.6421 - loss: 0.5885 - val_accuracy: 0.1207 - val_loss: 6.5809\n",
      "Epoch 121/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.6483 - loss: 0.5846 - val_accuracy: 0.1091 - val_loss: 6.5728\n",
      "Epoch 122/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.6505 - loss: 0.5856 - val_accuracy: 0.1034 - val_loss: 6.7098\n",
      "Epoch 123/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.6503 - loss: 0.5822 - val_accuracy: 0.0774 - val_loss: 6.3977\n",
      "Epoch 124/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6441 - loss: 0.5873 - val_accuracy: 0.1089 - val_loss: 6.3894\n",
      "Epoch 125/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.6378 - loss: 0.5907 - val_accuracy: 0.1112 - val_loss: 6.1675\n",
      "Epoch 126/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.6484 - loss: 0.5858 - val_accuracy: 0.0878 - val_loss: 5.9624\n",
      "Epoch 127/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.6460 - loss: 0.5895 - val_accuracy: 0.1042 - val_loss: 6.5419\n",
      "Epoch 128/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.6466 - loss: 0.5861 - val_accuracy: 0.0918 - val_loss: 6.6361\n",
      "Epoch 129/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.6436 - loss: 0.5873 - val_accuracy: 0.1004 - val_loss: 6.1494\n",
      "Epoch 130/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6498 - loss: 0.5838 - val_accuracy: 0.0835 - val_loss: 6.6267\n",
      "Epoch 131/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.6449 - loss: 0.5880 - val_accuracy: 0.1289 - val_loss: 6.6777\n",
      "Epoch 132/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.6394 - loss: 0.5923 - val_accuracy: 0.0890 - val_loss: 6.4095\n",
      "Epoch 133/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.6461 - loss: 0.5853 - val_accuracy: 0.1215 - val_loss: 7.0917\n",
      "Epoch 134/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.6478 - loss: 0.5868 - val_accuracy: 0.1281 - val_loss: 7.5381\n",
      "Epoch 135/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.6397 - loss: 0.5911 - val_accuracy: 0.0932 - val_loss: 8.1112\n",
      "Epoch 136/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6493 - loss: 0.5829 - val_accuracy: 0.1057 - val_loss: 7.2169\n",
      "Epoch 137/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.6443 - loss: 0.5859 - val_accuracy: 0.0852 - val_loss: 6.9288\n",
      "Epoch 138/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.6402 - loss: 0.5902 - val_accuracy: 0.0804 - val_loss: 6.6267\n",
      "Epoch 139/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.6475 - loss: 0.5855 - val_accuracy: 0.1036 - val_loss: 6.4864\n",
      "Epoch 140/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.6521 - loss: 0.5834 - val_accuracy: 0.1222 - val_loss: 5.8969\n",
      "Epoch 141/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6390 - loss: 0.5881 - val_accuracy: 0.1023 - val_loss: 6.4237\n",
      "Epoch 142/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - accuracy: 0.6531 - loss: 0.5822 - val_accuracy: 0.1078 - val_loss: 6.7369\n",
      "Epoch 143/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.6428 - loss: 0.5908 - val_accuracy: 0.0876 - val_loss: 6.3117\n",
      "Epoch 144/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.6532 - loss: 0.5830 - val_accuracy: 0.0992 - val_loss: 7.3111\n",
      "Epoch 145/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.6457 - loss: 0.5860 - val_accuracy: 0.0795 - val_loss: 7.6700\n",
      "Epoch 146/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.6518 - loss: 0.5804 - val_accuracy: 0.0973 - val_loss: 7.6089\n",
      "Epoch 147/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.6504 - loss: 0.5864 - val_accuracy: 0.1184 - val_loss: 6.8463\n",
      "Epoch 148/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.6541 - loss: 0.5815 - val_accuracy: 0.0949 - val_loss: 6.5121\n",
      "Epoch 149/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.6490 - loss: 0.5854 - val_accuracy: 0.0905 - val_loss: 7.4056\n",
      "Epoch 150/150\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.6545 - loss: 0.5830 - val_accuracy: 0.0848 - val_loss: 7.5055\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step\n",
      "Acurácia: 0.8242\n",
      "Sensibilidade (Recall): 0.0001\n",
      "AUC: 0.5000\n",
      "Especificidade: 0.9998\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Carregar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df1['num_ocorrencias'] = df1['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df1['num_ocorrencias']\n",
    "X_train = df1.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Balancear os dados usando undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, input_shape=(X_resampled.shape[1], 1), return_sequences=True))  # Primeira camada LSTM\n",
    "model.add(Dropout(0.4))  # Camada Dropout\n",
    "model.add(LSTM(units=100, return_sequences=True))  # Segunda camada LSTM\n",
    "model.add(Dropout(0.4))  # Camada Dropout\n",
    "model.add(LSTM(units=100, return_sequences=False))  # Última camada LSTM\n",
    "model.add(Dropout(0.4))  # Camada Dropout\n",
    "model.add(Dense(units=50, activation='relu'))  # Camada densa adicional\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Camada de saída\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar o X_resampled para o formato correto\n",
    "X_resampled_reshaped = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled_reshaped,\n",
    "    y_resampled,\n",
    "    epochs=150,  # Aumentando o número de épocas\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Preparar os dados de teste\n",
    "df2['num_ocorrencias'] = df2['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df2['num_ocorrencias']\n",
    "X_test = df2.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes no conjunto de teste\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote_Previsao_3cvs_2019-2023_v5.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6302 - loss: 0.6468 - val_accuracy: 0.5056 - val_loss: 0.6859\n",
      "Epoch 2/200\n",
      "\u001b[1m  3/333\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6059 - loss: 0.6347 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_auc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6340 - loss: 0.6396 - val_accuracy: 0.6398 - val_loss: 0.6125\n",
      "Epoch 3/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.6383 - loss: 0.6371 - val_accuracy: 0.6958 - val_loss: 0.5432\n",
      "Epoch 4/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6377 - loss: 0.6362 - val_accuracy: 0.6889 - val_loss: 0.5619\n",
      "Epoch 5/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6423 - loss: 0.6325 - val_accuracy: 0.5028 - val_loss: 0.7181\n",
      "Epoch 6/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6314 - loss: 0.6394 - val_accuracy: 0.6202 - val_loss: 0.6101\n",
      "Epoch 7/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6401 - loss: 0.6321 - val_accuracy: 0.6287 - val_loss: 0.6191\n",
      "Epoch 8/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.6343 - loss: 0.6339 - val_accuracy: 0.6018 - val_loss: 0.5859\n",
      "Epoch 9/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.6365 - loss: 0.6319 - val_accuracy: 0.5209 - val_loss: 0.6828\n",
      "Epoch 10/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.6378 - loss: 0.6304 - val_accuracy: 0.5120 - val_loss: 0.7195\n",
      "Epoch 11/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.6414 - loss: 0.6318 - val_accuracy: 0.7748 - val_loss: 0.5048\n",
      "Epoch 12/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6422 - loss: 0.6286 - val_accuracy: 0.5895 - val_loss: 0.6378\n",
      "Epoch 13/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.6348 - loss: 0.6287 - val_accuracy: 0.6891 - val_loss: 0.5355\n",
      "Epoch 14/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6413 - loss: 0.6302 - val_accuracy: 0.6448 - val_loss: 0.5832\n",
      "Epoch 15/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6403 - loss: 0.6267 - val_accuracy: 0.5214 - val_loss: 0.6858\n",
      "Epoch 16/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.6407 - loss: 0.6293 - val_accuracy: 0.4639 - val_loss: 0.7480\n",
      "Epoch 17/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6431 - loss: 0.6298 - val_accuracy: 0.6968 - val_loss: 0.5264\n",
      "Epoch 18/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6422 - loss: 0.6298 - val_accuracy: 0.6358 - val_loss: 0.5727\n",
      "Epoch 19/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6399 - loss: 0.6280 - val_accuracy: 0.6108 - val_loss: 0.6041\n",
      "Epoch 20/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6463 - loss: 0.6201 - val_accuracy: 0.6016 - val_loss: 0.6299\n",
      "Epoch 21/200\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.6421 - loss: 0.6255 - val_accuracy: 0.6287 - val_loss: 0.5960\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step\n",
      "Acurácia: 0.4289\n",
      "Sensibilidade (Recall): 0.7207\n",
      "AUC: 0.5437\n",
      "Especificidade: 0.3667\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step\n",
      "Acurácia no conjunto de teste (df3): 0.5287\n",
      "Sensibilidade (Recall) no conjunto de teste (df3): 0.7194\n",
      "AUC no conjunto de teste (df3): 0.5584\n",
      "Especificidade no conjunto de teste (df3): 0.3974\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN  # Importando SMOTE + ENN\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Carregar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df1['num_ocorrencias'] = df1['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df1['num_ocorrencias']\n",
    "X_train = df1.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Balancear os dados usando SMOTE + ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_resampled.shape[1], 1), return_sequences=True))  # Aumentar unidades\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=128, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar o X_resampled para o formato correto\n",
    "X_resampled_reshaped = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Callbacks para Early Stopping e Model Checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_auc', mode='max')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled_reshaped,\n",
    "    y_resampled,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v5.h5')\n",
    "\n",
    "# Preparar os dados de teste\n",
    "df2['num_ocorrencias'] = df2['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df2['num_ocorrencias']\n",
    "X_test = df2.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes no conjunto de teste\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n",
    "\n",
    "# Preparar os dados de teste final (df3)\n",
    "df3['num_ocorrencias'] = df3['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test_final = df3['num_ocorrencias']\n",
    "X_test_final = df3.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes no conjunto de teste\n",
    "X_test_final = imputer.transform(X_test_final)\n",
    "X_test_final_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Ajustar o X_test_final para o formato correto\n",
    "X_test_final_reshaped = X_test_final_scaled.reshape((X_test_final_scaled.shape[0], X_test_final_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_final_prob = model.predict(X_test_final_reshaped)\n",
    "y_pred_final = (y_pred_final_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas para df3\n",
    "accuracy_final = accuracy_score(y_test_final, y_pred_final)\n",
    "recall_final = recall_score(y_test_final, y_pred_final)\n",
    "roc_auc_final = roc_auc_score(y_test_final, y_pred_final)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn_final, fp_final, fn_final, tp_final = confusion_matrix(y_test_final, y_pred_final).ravel()\n",
    "specificity_final = tn_final / (tn_final + fp_final)\n",
    "\n",
    "# Imprimir as métricas para df3\n",
    "print(f'Acurácia no conjunto de teste (df3): {accuracy_final:.4f}')\n",
    "print(f'Sensibilidade (Recall) no conjunto de teste (df3): {recall_final:.4f}')\n",
    "print(f'AUC no conjunto de teste (df3): {roc_auc_final:.4f}')\n",
    "print(f'Especificidade no conjunto de teste (df3): {specificity_final:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_resampled: (111930, 4)\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.6242 - loss: 0.6554 - val_accuracy: 0.0618 - val_loss: 0.9370\n",
      "Epoch 2/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.6264 - loss: 0.6519 - val_accuracy: 0.1900 - val_loss: 0.9611\n",
      "Epoch 3/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6294 - loss: 0.6514 - val_accuracy: 0.1790 - val_loss: 0.8517\n",
      "Epoch 4/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 0.6520 - val_accuracy: 0.1040 - val_loss: 0.9702\n",
      "Epoch 5/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6280 - loss: 0.6505 - val_accuracy: 0.1093 - val_loss: 0.9090\n",
      "Epoch 6/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6287 - loss: 0.6494 - val_accuracy: 0.1419 - val_loss: 0.9420\n",
      "Epoch 7/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6290 - loss: 0.6503 - val_accuracy: 0.2899 - val_loss: 0.8504\n",
      "Epoch 8/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6264 - loss: 0.6509 - val_accuracy: 0.0812 - val_loss: 0.9708\n",
      "Epoch 9/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6291 - loss: 0.6506 - val_accuracy: 0.0486 - val_loss: 1.0586\n",
      "Epoch 10/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6260 - loss: 0.6514 - val_accuracy: 0.1377 - val_loss: 0.9895\n",
      "Epoch 11/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6288 - loss: 0.6487 - val_accuracy: 0.0293 - val_loss: 1.0638\n",
      "Epoch 12/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6298 - loss: 0.6484 - val_accuracy: 0.0964 - val_loss: 1.0864\n",
      "Epoch 13/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6268 - loss: 0.6495 - val_accuracy: 0.1665 - val_loss: 0.9993\n",
      "Epoch 14/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6296 - loss: 0.6484 - val_accuracy: 0.2396 - val_loss: 0.9155\n",
      "Epoch 15/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 11ms/step - accuracy: 0.6306 - loss: 0.6482 - val_accuracy: 0.0730 - val_loss: 1.0771\n",
      "Epoch 16/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6278 - loss: 0.6496 - val_accuracy: 0.0797 - val_loss: 1.0342\n",
      "Epoch 17/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6277 - loss: 0.6494 - val_accuracy: 0.1102 - val_loss: 1.0244\n",
      "Epoch 18/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6293 - loss: 0.6481 - val_accuracy: 0.1071 - val_loss: 0.9450\n",
      "Epoch 19/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6275 - loss: 0.6485 - val_accuracy: 0.1577 - val_loss: 0.9770\n",
      "Epoch 20/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6293 - loss: 0.6476 - val_accuracy: 0.2009 - val_loss: 0.9872\n",
      "Epoch 21/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6275 - loss: 0.6488 - val_accuracy: 0.2186 - val_loss: 0.8792\n",
      "Epoch 22/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6293 - loss: 0.6466 - val_accuracy: 0.1171 - val_loss: 0.9931\n",
      "Epoch 23/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6291 - loss: 0.6473 - val_accuracy: 0.1908 - val_loss: 0.9712\n",
      "Epoch 24/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6293 - loss: 0.6481 - val_accuracy: 0.1470 - val_loss: 0.9587\n",
      "Epoch 25/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6305 - loss: 0.6477 - val_accuracy: 0.2104 - val_loss: 0.9017\n",
      "Epoch 26/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6282 - loss: 0.6483 - val_accuracy: 0.1365 - val_loss: 0.9503\n",
      "Epoch 27/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6295 - loss: 0.6468 - val_accuracy: 0.0615 - val_loss: 1.0049\n",
      "Epoch 28/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6306 - loss: 0.6462 - val_accuracy: 0.0755 - val_loss: 0.9601\n",
      "Epoch 29/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6283 - loss: 0.6489 - val_accuracy: 0.1321 - val_loss: 0.9699\n",
      "Epoch 30/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6314 - loss: 0.6460 - val_accuracy: 0.0625 - val_loss: 0.9848\n",
      "Epoch 31/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 0.6466 - val_accuracy: 0.1498 - val_loss: 0.9261\n",
      "Epoch 32/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6300 - loss: 0.6469 - val_accuracy: 0.1962 - val_loss: 0.9440\n",
      "Epoch 33/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6299 - loss: 0.6460 - val_accuracy: 0.2168 - val_loss: 0.8735\n",
      "Epoch 34/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6305 - loss: 0.6465 - val_accuracy: 0.2095 - val_loss: 0.9745\n",
      "Epoch 35/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.6267 - loss: 0.6489 - val_accuracy: 0.1750 - val_loss: 0.9765\n",
      "Epoch 36/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6279 - loss: 0.6471 - val_accuracy: 0.2008 - val_loss: 0.8895\n",
      "Epoch 37/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6295 - loss: 0.6468 - val_accuracy: 0.2370 - val_loss: 0.9093\n",
      "Epoch 38/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6280 - loss: 0.6477 - val_accuracy: 0.2127 - val_loss: 0.9214\n",
      "Epoch 39/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6291 - loss: 0.6463 - val_accuracy: 0.0738 - val_loss: 1.0219\n",
      "Epoch 40/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6338 - loss: 0.6444 - val_accuracy: 0.1436 - val_loss: 0.9286\n",
      "Epoch 41/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6286 - loss: 0.6470 - val_accuracy: 0.2157 - val_loss: 0.9509\n",
      "Epoch 42/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6298 - loss: 0.6463 - val_accuracy: 0.1672 - val_loss: 0.9079\n",
      "Epoch 43/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: 0.6478 - val_accuracy: 0.0844 - val_loss: 1.0056\n",
      "Epoch 44/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - accuracy: 0.6316 - loss: 0.6454 - val_accuracy: 0.0264 - val_loss: 0.9681\n",
      "Epoch 45/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6282 - loss: 0.6453 - val_accuracy: 0.1131 - val_loss: 0.9642\n",
      "Epoch 46/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6306 - loss: 0.6460 - val_accuracy: 0.1747 - val_loss: 0.9380\n",
      "Epoch 47/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6324 - loss: 0.6455 - val_accuracy: 0.2209 - val_loss: 0.9071\n",
      "Epoch 48/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 12ms/step - accuracy: 0.6313 - loss: 0.6465 - val_accuracy: 0.1713 - val_loss: 0.9448\n",
      "Epoch 49/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6326 - loss: 0.6452 - val_accuracy: 0.2433 - val_loss: 0.9256\n",
      "Epoch 50/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6308 - loss: 0.6459 - val_accuracy: 0.1015 - val_loss: 0.9916\n",
      "Epoch 51/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6297 - loss: 0.6467 - val_accuracy: 0.2316 - val_loss: 0.9485\n",
      "Epoch 52/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6281 - loss: 0.6463 - val_accuracy: 0.3173 - val_loss: 0.8533\n",
      "Epoch 53/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6313 - loss: 0.6451 - val_accuracy: 0.2158 - val_loss: 0.9111\n",
      "Epoch 54/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6351 - loss: 0.6432 - val_accuracy: 0.1587 - val_loss: 0.9967\n",
      "Epoch 55/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6290 - loss: 0.6466 - val_accuracy: 0.1961 - val_loss: 0.9538\n",
      "Epoch 56/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6327 - loss: 0.6456 - val_accuracy: 0.2283 - val_loss: 0.9209\n",
      "Epoch 57/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - accuracy: 0.6289 - loss: 0.6472 - val_accuracy: 0.1454 - val_loss: 1.0231\n",
      "Epoch 58/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.6463 - val_accuracy: 0.1952 - val_loss: 0.9185\n",
      "Epoch 59/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6303 - loss: 0.6456 - val_accuracy: 0.1268 - val_loss: 0.8935\n",
      "Epoch 60/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: 0.6466 - val_accuracy: 0.1247 - val_loss: 0.9516\n",
      "Epoch 61/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6302 - loss: 0.6470 - val_accuracy: 0.1597 - val_loss: 0.9494\n",
      "Epoch 62/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6326 - loss: 0.6442 - val_accuracy: 0.1537 - val_loss: 0.9363\n",
      "Epoch 63/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: 0.6470 - val_accuracy: 0.1067 - val_loss: 0.9675\n",
      "Epoch 64/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6310 - loss: 0.6453 - val_accuracy: 0.0914 - val_loss: 0.9538\n",
      "Epoch 65/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6303 - loss: 0.6453 - val_accuracy: 0.1600 - val_loss: 0.9238\n",
      "Epoch 66/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6298 - loss: 0.6445 - val_accuracy: 0.1171 - val_loss: 0.9693\n",
      "Epoch 67/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6303 - loss: 0.6457 - val_accuracy: 0.1957 - val_loss: 0.9416\n",
      "Epoch 68/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6331 - loss: 0.6441 - val_accuracy: 0.1519 - val_loss: 0.9609\n",
      "Epoch 69/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6304 - loss: 0.6446 - val_accuracy: 0.1713 - val_loss: 0.9313\n",
      "Epoch 70/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6292 - loss: 0.6461 - val_accuracy: 0.2053 - val_loss: 0.9939\n",
      "Epoch 71/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6287 - loss: 0.6466 - val_accuracy: 0.2035 - val_loss: 0.9675\n",
      "Epoch 72/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6310 - loss: 0.6454 - val_accuracy: 0.1958 - val_loss: 0.9672\n",
      "Epoch 73/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6305 - loss: 0.6447 - val_accuracy: 0.1259 - val_loss: 0.9667\n",
      "Epoch 74/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6297 - loss: 0.6458 - val_accuracy: 0.1958 - val_loss: 0.9239\n",
      "Epoch 75/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6306 - loss: 0.6458 - val_accuracy: 0.0503 - val_loss: 1.0269\n",
      "Epoch 76/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6319 - loss: 0.6449 - val_accuracy: 0.1020 - val_loss: 1.0165\n",
      "Epoch 77/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6326 - loss: 0.6439 - val_accuracy: 0.2280 - val_loss: 0.9852\n",
      "Epoch 78/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6322 - loss: 0.6440 - val_accuracy: 0.1788 - val_loss: 0.9435\n",
      "Epoch 79/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6305 - loss: 0.6455 - val_accuracy: 0.1641 - val_loss: 0.9838\n",
      "Epoch 80/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 0.6454 - val_accuracy: 0.2001 - val_loss: 0.8975\n",
      "Epoch 81/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6299 - loss: 0.6450 - val_accuracy: 0.1819 - val_loss: 0.9194\n",
      "Epoch 82/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6325 - loss: 0.6446 - val_accuracy: 0.1927 - val_loss: 0.9483\n",
      "Epoch 83/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6311 - loss: 0.6444 - val_accuracy: 0.1664 - val_loss: 0.9472\n",
      "Epoch 84/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6335 - loss: 0.6434 - val_accuracy: 0.0772 - val_loss: 0.9986\n",
      "Epoch 85/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6307 - loss: 0.6447 - val_accuracy: 0.1491 - val_loss: 0.9631\n",
      "Epoch 86/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6309 - loss: 0.6452 - val_accuracy: 0.0928 - val_loss: 1.0242\n",
      "Epoch 87/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6295 - loss: 0.6447 - val_accuracy: 0.1310 - val_loss: 0.9695\n",
      "Epoch 88/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6324 - loss: 0.6437 - val_accuracy: 0.1055 - val_loss: 0.9668\n",
      "Epoch 89/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.6438 - val_accuracy: 0.1169 - val_loss: 0.9346\n",
      "Epoch 90/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6312 - loss: 0.6451 - val_accuracy: 0.2087 - val_loss: 0.9576\n",
      "Epoch 91/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6308 - loss: 0.6439 - val_accuracy: 0.1127 - val_loss: 0.9871\n",
      "Epoch 92/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6304 - loss: 0.6458 - val_accuracy: 0.1739 - val_loss: 0.9732\n",
      "Epoch 93/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6302 - loss: 0.6449 - val_accuracy: 0.1042 - val_loss: 0.9925\n",
      "Epoch 94/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6291 - loss: 0.6459 - val_accuracy: 0.1800 - val_loss: 0.9348\n",
      "Epoch 95/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6339 - loss: 0.6426 - val_accuracy: 0.1005 - val_loss: 1.0112\n",
      "Epoch 96/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.6344 - loss: 0.6435 - val_accuracy: 0.0886 - val_loss: 0.9529\n",
      "Epoch 97/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6309 - loss: 0.6452 - val_accuracy: 0.1699 - val_loss: 0.9518\n",
      "Epoch 98/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6306 - loss: 0.6463 - val_accuracy: 0.1419 - val_loss: 0.9649\n",
      "Epoch 99/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6294 - loss: 0.6451 - val_accuracy: 0.2228 - val_loss: 0.8933\n",
      "Epoch 100/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 12ms/step - accuracy: 0.6317 - loss: 0.6442 - val_accuracy: 0.0687 - val_loss: 0.9955\n",
      "Epoch 101/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6340 - loss: 0.6420 - val_accuracy: 0.1343 - val_loss: 0.9835\n",
      "Epoch 102/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6368 - loss: 0.6422 - val_accuracy: 0.1730 - val_loss: 0.9393\n",
      "Epoch 103/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6321 - loss: 0.6432 - val_accuracy: 0.0812 - val_loss: 0.9530\n",
      "Epoch 104/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6328 - loss: 0.6439 - val_accuracy: 0.1645 - val_loss: 0.9544\n",
      "Epoch 105/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6298 - loss: 0.6461 - val_accuracy: 0.0983 - val_loss: 0.9820\n",
      "Epoch 106/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6298 - loss: 0.6453 - val_accuracy: 0.1300 - val_loss: 0.9599\n",
      "Epoch 107/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6291 - loss: 0.6457 - val_accuracy: 0.2012 - val_loss: 0.9457\n",
      "Epoch 108/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6296 - loss: 0.6439 - val_accuracy: 0.2129 - val_loss: 0.9897\n",
      "Epoch 109/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6317 - loss: 0.6439 - val_accuracy: 0.2057 - val_loss: 0.9283\n",
      "Epoch 110/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6318 - loss: 0.6438 - val_accuracy: 0.2344 - val_loss: 0.9198\n",
      "Epoch 111/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6318 - loss: 0.6449 - val_accuracy: 0.2207 - val_loss: 0.9690\n",
      "Epoch 112/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6322 - loss: 0.6430 - val_accuracy: 0.2334 - val_loss: 0.9128\n",
      "Epoch 113/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6309 - loss: 0.6441 - val_accuracy: 0.1867 - val_loss: 0.9543\n",
      "Epoch 114/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6302 - loss: 0.6440 - val_accuracy: 0.2434 - val_loss: 0.9275\n",
      "Epoch 115/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6339 - loss: 0.6433 - val_accuracy: 0.1468 - val_loss: 0.9509\n",
      "Epoch 116/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6305 - loss: 0.6435 - val_accuracy: 0.1454 - val_loss: 0.9093\n",
      "Epoch 117/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6280 - loss: 0.6450 - val_accuracy: 0.1379 - val_loss: 0.9858\n",
      "Epoch 118/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.6427 - val_accuracy: 0.1498 - val_loss: 0.9333\n",
      "Epoch 119/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6353 - loss: 0.6431 - val_accuracy: 0.2172 - val_loss: 0.9322\n",
      "Epoch 120/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6308 - loss: 0.6434 - val_accuracy: 0.1697 - val_loss: 0.9480\n",
      "Epoch 121/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6299 - loss: 0.6449 - val_accuracy: 0.0943 - val_loss: 0.9630\n",
      "Epoch 122/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6308 - loss: 0.6449 - val_accuracy: 0.2683 - val_loss: 0.9138\n",
      "Epoch 123/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - accuracy: 0.6335 - loss: 0.6440 - val_accuracy: 0.1065 - val_loss: 0.9506\n",
      "Epoch 124/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6298 - loss: 0.6444 - val_accuracy: 0.1055 - val_loss: 0.9703\n",
      "Epoch 125/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6325 - loss: 0.6431 - val_accuracy: 0.1560 - val_loss: 0.9571\n",
      "Epoch 126/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6327 - loss: 0.6439 - val_accuracy: 0.2166 - val_loss: 0.9119\n",
      "Epoch 127/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6312 - loss: 0.6444 - val_accuracy: 0.1144 - val_loss: 0.9556\n",
      "Epoch 128/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6301 - loss: 0.6437 - val_accuracy: 0.1214 - val_loss: 0.9437\n",
      "Epoch 129/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6357 - loss: 0.6418 - val_accuracy: 0.1879 - val_loss: 0.9288\n",
      "Epoch 130/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6319 - loss: 0.6446 - val_accuracy: 0.1777 - val_loss: 0.9474\n",
      "Epoch 131/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 0.6448 - val_accuracy: 0.1806 - val_loss: 0.9290\n",
      "Epoch 132/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6331 - loss: 0.6423 - val_accuracy: 0.0624 - val_loss: 1.0383\n",
      "Epoch 133/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - accuracy: 0.6310 - loss: 0.6440 - val_accuracy: 0.0871 - val_loss: 0.9946\n",
      "Epoch 134/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6306 - loss: 0.6443 - val_accuracy: 0.1829 - val_loss: 0.9484\n",
      "Epoch 135/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - accuracy: 0.6327 - loss: 0.6431 - val_accuracy: 0.0876 - val_loss: 0.9614\n",
      "Epoch 136/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6327 - loss: 0.6435 - val_accuracy: 0.1982 - val_loss: 0.9172\n",
      "Epoch 137/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.6426 - val_accuracy: 0.1304 - val_loss: 0.9689\n",
      "Epoch 138/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6319 - loss: 0.6438 - val_accuracy: 0.1217 - val_loss: 0.9655\n",
      "Epoch 139/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6321 - loss: 0.6415 - val_accuracy: 0.1718 - val_loss: 0.9503\n",
      "Epoch 140/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6342 - loss: 0.6425 - val_accuracy: 0.1117 - val_loss: 0.9504\n",
      "Epoch 141/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6366 - loss: 0.6420 - val_accuracy: 0.1890 - val_loss: 0.9714\n",
      "Epoch 142/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - accuracy: 0.6329 - loss: 0.6435 - val_accuracy: 0.1977 - val_loss: 0.9424\n",
      "Epoch 143/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6330 - loss: 0.6427 - val_accuracy: 0.1092 - val_loss: 0.9559\n",
      "Epoch 144/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6318 - loss: 0.6427 - val_accuracy: 0.1133 - val_loss: 0.9391\n",
      "Epoch 145/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.6317 - loss: 0.6436 - val_accuracy: 0.0849 - val_loss: 0.9810\n",
      "Epoch 146/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.6319 - loss: 0.6439 - val_accuracy: 0.1358 - val_loss: 0.9206\n",
      "Epoch 147/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6320 - loss: 0.6413 - val_accuracy: 0.0439 - val_loss: 0.9594\n",
      "Epoch 148/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.6299 - loss: 0.6433 - val_accuracy: 0.1188 - val_loss: 0.9412\n",
      "Epoch 149/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.6354 - loss: 0.6414 - val_accuracy: 0.1789 - val_loss: 0.9013\n",
      "Epoch 150/150\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.6313 - loss: 0.6435 - val_accuracy: 0.1943 - val_loss: 0.9534\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
      "Acurácia: 0.7193\n",
      "Sensibilidade (Recall): 0.2959\n",
      "AUC: 0.5527\n",
      "Especificidade: 0.8096\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Carregar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Concatenar df1 e df3 para o conjunto de treino\n",
    "df_train = pd.concat([df1, df3])\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df_train['num_ocorrencias'] = df_train['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df_train['num_ocorrencias']\n",
    "X_train = df_train.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Preparar o conjunto de teste\n",
    "df2['num_ocorrencias'] = df2['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df2['num_ocorrencias']\n",
    "X_test = df2.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes (preenchendo com a média das colunas, por exemplo)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicar SMOTE para aumentar a classe minoritária\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)  # Gerando amostras da classe minoritária\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Aplicar Undersampling na classe majoritária\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)  # Reduzindo a classe majoritária\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Verificar a forma de X_resampled\n",
    "print(f\"Forma de X_resampled: {X_resampled.shape}\")\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_resampled.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=128, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar o X_resampled para o formato correto\n",
    "X_resampled_reshaped = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled_reshaped,\n",
    "    y_resampled,\n",
    "    epochs=150,  \n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Preparar o conjunto de teste para previsão\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN  # Importando SMOTE + ENN\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Carregar os dados\n",
    "df1 = pd.read_csv('clima_queda_parelheiros_2019-2023.csv')\n",
    "df2 = pd.read_csv('clima_queda_santana_2019-2023.csv')\n",
    "df3 = pd.read_csv('clima_queda_virginha_2019-2023.csv')\n",
    "\n",
    "# Criar a coluna de ocorrências (0 ou 1)\n",
    "df1['num_ocorrencias'] = df1['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_train = df1['num_ocorrencias']\n",
    "X_train = df1.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Balancear os dados usando SMOTE + ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Criar o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_resampled.shape[1], 1), return_sequences=True))  # Aumentar unidades\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=128, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar o X_resampled para o formato correto\n",
    "X_resampled_reshaped = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Callbacks para Early Stopping e Model Checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_auc', mode='max')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    X_resampled_reshaped,\n",
    "    y_resampled,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('Smote_Previsao_3cvs_2019-2023_v5.h5')\n",
    "\n",
    "# Preparar os dados de teste\n",
    "df2['num_ocorrencias'] = df2['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test = df2['num_ocorrencias']\n",
    "X_test = df2.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes no conjunto de teste\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ajustar o X_test para o formato correto\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Sensibilidade (Recall): {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'Especificidade: {specificity:.4f}')\n",
    "\n",
    "# Preparar os dados de teste final (df3)\n",
    "df3['num_ocorrencias'] = df3['num_ocorrencias'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test_final = df3['num_ocorrencias']\n",
    "X_test_final = df3.drop('num_ocorrencias', axis=1)\n",
    "\n",
    "# Imputar valores ausentes no conjunto de teste\n",
    "X_test_final = imputer.transform(X_test_final)\n",
    "X_test_final_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Ajustar o X_test_final para o formato correto\n",
    "X_test_final_reshaped = X_test_final_scaled.reshape((X_test_final_scaled.shape[0], X_test_final_scaled.shape[1], 1))\n",
    "\n",
    "# Prever usando o modelo treinado\n",
    "y_pred_final_prob = model.predict(X_test_final_reshaped)\n",
    "y_pred_final = (y_pred_final_prob > 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas para df3\n",
    "accuracy_final = accuracy_score(y_test_final, y_pred_final)\n",
    "recall_final = recall_score(y_test_final, y_pred_final)\n",
    "roc_auc_final = roc_auc_score(y_test_final, y_pred_final)\n",
    "\n",
    "# Calcular especificidade\n",
    "tn_final, fp_final, fn_final, tp_final = confusion_matrix(y_test_final, y_pred_final).ravel()\n",
    "specificity_final = tn_final / (tn_final + fp_final)\n",
    "\n",
    "# Imprimir as métricas para df3\n",
    "print(f'Acurácia no conjunto de teste (df3): {accuracy_final:.4f}')\n",
    "print(f'Sensibilidade (Recall) no conjunto de teste (df3): {recall_final:.4f}')\n",
    "print(f'AUC no conjunto de teste (df3): {roc_auc_final:.4f}')\n",
    "print(f'Especificidade no conjunto de teste (df3): {specificity_final:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
